{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzM1eJDG-JUY"
      },
      "source": [
        "# Laboratory #3_1 : Face detection and recognition\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Face detection\n",
        "    *   Integral images\n",
        "    *   Haar-like feature computation\n",
        "    *   Adaboost \n",
        "*   Face recognition\n",
        "    *   Eigen Faces\n",
        "    *   PCA\n",
        "\n",
        "**Remember this is a graded exercise.**\n",
        "\n",
        "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
        "*   Create reusable functions where ever possible, so that the code could be reused at different places.\n",
        "*   Mount your drive to access the images.\n",
        "*   Add sufficient comments and explanations wherever necessary.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19bkGE6ZJ5CYbfpyyy1BpDkMM3fD9xA1u?usp=sharing)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJIC9t_DV7js"
      },
      "source": [
        "# mount drive to the notebook\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7dwXBH83V1W"
      },
      "source": [
        "# Face Detection using AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mozS11CSt4sz"
      },
      "source": [
        "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
        "\n",
        "import numpy as np\n",
        "from skimage import data, io\n",
        "import os\n",
        "import matplotlib\n",
        "from PIL import Image\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "import time\n",
        "import timeit\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcu2FUj856xz"
      },
      "source": [
        "### Exercise #1\n",
        "\n",
        "*   Build a function compute_integral_image that computes the integral image of an input (2D) array. In an integral image each pixel is the sum of all pixels in the original image that are 'left and above' the pixel. See the following example:\n",
        "\n",
        "```\n",
        "Original    Integral\n",
        "+--------   +------------\n",
        "| 1 2 3 .   | 0  0  0  0 .\n",
        "| 4 5 6 .   | 0  1  3  6 .\n",
        "| . . . .   | 0  5 12 21 .\n",
        "            | . . . . . .\n",
        "```\n",
        "\n",
        "*   The integral image must have an additional row and column full of zeros (first row and first column).\n",
        "*   Plot the output of the integral image for the following array:\n",
        "\n",
        "```\n",
        "img_array = np.array([[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1]])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bAnhO5i3zs5"
      },
      "source": [
        "def compute_integral_image(img_arr):\n",
        "    \"\"\"\n",
        "    Calculates the integral image based on the original image data.\n",
        "    :param img_arr: Image source data\n",
        "    :type img_arr: numpy.ndarray\n",
        "    :return Integral image for given image\n",
        "    :rtype: numpy.ndarray\n",
        "    \"\"\"\n",
        "    # an index of -1 refers to the last row/column\n",
        "    # since row_sum is calculated starting from (0,0),\n",
        "    # rowSum(x, -1) == 0 holds for all x\n",
        "    row_sum = np.zeros(img_arr.shape)\n",
        "    # we need an additional column and row\n",
        "    integral_image_arr = np.zeros((img_arr.shape[0] + 1, img_arr.shape[1] + 1))\n",
        "\n",
        "    \n",
        "    # Add code here\n",
        "\n",
        "\n",
        "    return integral_image_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTAqVHSp-OMf"
      },
      "source": [
        "img_array = np.array([[1, 2, 2, 2, 1], [1, 2, 2, 2, 1], [1, 2, 2, 2, 1], [1, 2, 2, 2, 1]])\n",
        "plt.imshow(img_array, cmap=\"gray\", vmin=0, vmax= 5)\n",
        "plt.title(\"Array image\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-PJakhX9W6Z"
      },
      "source": [
        "ii_img_array = compute_integral_image(img_array)\n",
        "print(ii_img_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy6EhVNxusBd"
      },
      "source": [
        "*   Test the function using 'camera' image from the data module. Plot the original image and the integral image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVjtmJ-Wu09i"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8_9CkCk9n2P"
      },
      "source": [
        "### Exercise #2\n",
        "\n",
        "*   Create a function sum_region to compute the sum of the pixel intensities within a rectangle using the integral image. The rectangle will be defined using the top left (x, y) and bottom right (x, y) coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU24XMd892Mw"
      },
      "source": [
        "def sum_region(integral_img_arr, top_left, bottom_right):\n",
        "\n",
        "    \n",
        "    # Add code here\n",
        "    \n",
        "    \n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "631_iCxd-u0o"
      },
      "source": [
        "*   Make the following tests:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T3Xk2tm-vt7"
      },
      "source": [
        "# result you should get (12)\n",
        "print(sum_region(ii_img_array, [1, 1], [3, 4]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdUOIZ1G-9Ex"
      },
      "source": [
        "# result you should get (32)\n",
        "print(sum_region(ii_img_array, [0, 0], [-1, -1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7JG9MJ9_HXT"
      },
      "source": [
        "### Exercise #3\n",
        "\n",
        "*   Build a function load_integral_images to read all the images inside a given folder and compute the integral image of every image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwYt5HmA_TnD"
      },
      "source": [
        "def load_integral_images(path):\n",
        "    ii_images = []\n",
        "    for _file in os.listdir(path):\n",
        "        \n",
        "        \n",
        "        #### Complete here:\n",
        "        #### Read image\n",
        "        #### Remember to scale the images (with the max pixel intensity value)\n",
        "        \n",
        "\n",
        "    return ii_images\n",
        "\n",
        "\n",
        "# With this function we are reading each file in the folder, calculating its integral image and after that normalizing the image.\n",
        "# Finally we put our processed image in the list that we will return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1TnCyeV4LJ2"
      },
      "source": [
        "*   Use the load_integral_images function to compute the integral images of training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_tI5926_fO8"
      },
      "source": [
        "# change paths to your location\n",
        "\n",
        "root_dir = r''\n",
        "\n",
        "pos_training_path = os.path.join(root_dir, 'train_data/faces')\n",
        "neg_training_path = os.path.join(root_dir, 'train_data/non_faces')\n",
        "pos_testing_path = os.path.join(root_dir, 'test_data/faces')\n",
        "neg_testing_path = os.path.join(root_dir, 'test_data/non_faces')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLZ1R4JR_Hh0"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSqDBYX_FbF8"
      },
      "source": [
        "*   Visualize a few original images and the corresponding integral images using matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsMTKwfQAuFn"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPrncRBJvxJo"
      },
      "source": [
        "### Exercise #4\n",
        "\n",
        "*   Compute the Haar features of an image.\n",
        "*   We provide you with HaarLikeFeature class that has build in a get_score function and a get_vote function. Your job is to complete the code of the method _create_features in the class HaarLikeFeature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMcmkZIWwNJ0"
      },
      "source": [
        "def enum(**enums):\n",
        "    return type('Enum', (), enums)\n",
        "\n",
        "FeatureType = enum(TWO_VERTICAL=(1, 2), TWO_HORIZONTAL=(2, 1), THREE_HORIZONTAL=(3, 1), THREE_VERTICAL=(1, 3), FOUR=(2, 2))\n",
        "FeatureTypes = [FeatureType.TWO_VERTICAL, FeatureType.TWO_HORIZONTAL, FeatureType.THREE_VERTICAL, FeatureType.THREE_HORIZONTAL, FeatureType.FOUR]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M_hQ6zwwVP5"
      },
      "source": [
        "class HaarLikeFeature(object):\n",
        "    \"\"\"\n",
        "    Class representing a haar-like feature.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_type, position, width, height, threshold, polarity):\n",
        "        \"\"\"\n",
        "        Creates a new haar-like feature.\n",
        "        :param feature_type: Type of new feature, see FeatureType enum\n",
        "        :type feature_type: HaarLikeFeature.FeatureTypes\n",
        "        :param position: Top left corner where the feature begins (x, y)\n",
        "        :type position: (int, int)\n",
        "        :param width: Width of the feature\n",
        "        :type width: int\n",
        "        :param height: Height of the feature\n",
        "        :type height: int\n",
        "        :param threshold: Feature threshold\n",
        "        :type threshold: float\n",
        "        :param polarity: polarity of the feature -1 or 1\n",
        "        :type polarity: int\n",
        "        \"\"\"\n",
        "        self.type = feature_type\n",
        "        self.top_left = position\n",
        "        self.bottom_right = (position[0] + width, position[1] + height)\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.threshold = threshold\n",
        "        self.polarity = polarity\n",
        "        self.weight = 1\n",
        "    \n",
        "    def get_score(self, int_img):\n",
        "        \"\"\"\n",
        "        Get score for given integral image array.\n",
        "        :param int_img: Integral image array\n",
        "        :type int_img: numpy.ndarray\n",
        "        \n",
        "        :return: Score for given feature\n",
        "        :rtype: float\n",
        "        \"\"\"\n",
        "        score = 0\n",
        "        if self.type == FeatureType.TWO_VERTICAL:\n",
        "            first = sum_region(int_img, self.top_left, (self.top_left[0] + self.width, int(self.top_left[1] + self.height / 2)))\n",
        "            second = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 2)), self.bottom_right)\n",
        "            score = first - second\n",
        "        elif self.type == FeatureType.TWO_HORIZONTAL:\n",
        "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 2), self.top_left[1] + self.height))\n",
        "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 2), self.top_left[1]), self.bottom_right)\n",
        "            score = first - second\n",
        "        elif self.type == FeatureType.THREE_HORIZONTAL:\n",
        "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 3), self.top_left[1] + self.height))\n",
        "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 3), self.top_left[1]), (int(self.top_left[0] + 2 * self.width / 3), self.top_left[1] + self.height))\n",
        "            third = sum_region(int_img, (int(self.top_left[0] + 2 * self.width / 3), self.top_left[1]), self.bottom_right)\n",
        "            score = first - second + third\n",
        "        elif self.type == FeatureType.THREE_VERTICAL:\n",
        "            first = sum_region(int_img, self.top_left, (self.bottom_right[0], int(self.top_left[1] + self.height / 3)))\n",
        "            second = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 3)), (self.bottom_right[0], int(self.top_left[1] + 2 * self.height / 3)))\n",
        "            third = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + 2 * self.height / 3)), self.bottom_right)\n",
        "            score = first - second + third\n",
        "        elif self.type == FeatureType.FOUR:\n",
        "            # top left area\n",
        "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 2), int(self.top_left[1] + self.height / 2)))\n",
        "            # top right area\n",
        "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 2), self.top_left[1]), (self.bottom_right[0], int(self.top_left[1] + self.height / 2)))\n",
        "            # bottom left area\n",
        "            third = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 2)), (int(self.top_left[0] + self.width / 2), self.bottom_right[1]))\n",
        "            # bottom right area\n",
        "            fourth = sum_region(int_img, (int(self.top_left[0] + self.width / 2), int(self.top_left[1] + self.height / 2)), self.bottom_right)\n",
        "            score = first - second - third + fourth\n",
        "        return score\n",
        "    \n",
        "    def get_vote(self, int_img):\n",
        "        \"\"\"\n",
        "        Get vote of this feature for given integral image.\n",
        "        :param int_img: Integral image array\n",
        "        :type int_img: numpy.ndarray\n",
        "        \n",
        "        :return: 1 iff this feature votes positively, otherwise -1\n",
        "        :rtype: int\n",
        "        \"\"\"\n",
        "        score = self.get_score(int_img)\n",
        "        return self.weight * (1 if score < self.polarity * self.threshold else -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Bv1TanwqEH"
      },
      "source": [
        "def learn(positive_iis, negative_iis, num_classifiers=-1, min_feature_width=1, max_feature_width=-1, min_feature_height=1, max_feature_height=-1):\n",
        "    \"\"\"\n",
        "    Selects a set of classifiers. Iteratively takes the best classifiers based\n",
        "    on a weighted error.\n",
        "    :param positive_iis: List of positive integral image examples\n",
        "    :type positive_iis: list[numpy.ndarray]\n",
        "    :param negative_iis: List of negative integral image examples\n",
        "    :type negative_iis: list[numpy.ndarray]\n",
        "    :param num_classifiers: Number of classifiers to select, -1 will use all\n",
        "    classifiers\n",
        "    :type num_classifiers: int\n",
        "    \n",
        "    :return: List of selected features\n",
        "    :rtype: list[HaarLikeFeature.HaarLikeFeature]\n",
        "    \"\"\"\n",
        "    num_pos = len(positive_iis)\n",
        "    num_neg = len(negative_iis)\n",
        "    num_imgs = num_pos + num_neg\n",
        "    img_height, img_width = positive_iis[0].shape\n",
        "\n",
        "    # Maximum feature width and height default to image width and height\n",
        "    max_feature_height = img_height if max_feature_height == -1 else max_feature_height\n",
        "    max_feature_width = img_width if max_feature_width == -1 else max_feature_width\n",
        "\n",
        "    # Create initial weights and labels\n",
        "    pos_weights = np.ones(num_pos) * 1. / (2 * num_pos)\n",
        "    neg_weights = np.ones(num_neg) * 1. / (2 * num_neg)\n",
        "    weights = np.hstack((pos_weights, neg_weights))\n",
        "    labels = np.hstack((np.ones(num_pos), np.ones(num_neg) * -1)) \n",
        "\n",
        "    images = positive_iis + negative_iis\n",
        "\n",
        "    # Create features for all sizes and locations\n",
        "    features = _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height)\n",
        "    num_features = len(features)\n",
        "    feature_indexes = list(range(num_features))\n",
        "\n",
        "    num_classifiers = num_features if num_classifiers == -1 else num_classifiers\n",
        "\n",
        "    print('Calculating scores for images..')\n",
        "    t0 = time.time()\n",
        "    votes = np.zeros((num_imgs, num_features))\n",
        "    # Use as many workers as there are CPUs\n",
        "    pool = Pool(processes=8)\n",
        "    for i in range(num_imgs):\n",
        "        votes[i, :] = np.array(list(pool.map(partial(_get_feature_vote, image=images[i]), features)))\n",
        "\n",
        "    \n",
        "    print('\\tTime needed for calculating scores:', time.time()-t0)\n",
        "    \n",
        "    # select classifiers\n",
        "    classifiers = []\n",
        "\n",
        "    t0 = time.time()\n",
        "    print('Selecting classifiers..')\n",
        "    for _ in range(num_classifiers):\n",
        "\n",
        "        classification_errors = np.zeros(len(feature_indexes))\n",
        "\n",
        "        # normalize weights\n",
        "        weights *= 1. / np.sum(weights)\n",
        "\n",
        "        # select best classifier based on the weighted error\n",
        "        for f in range(len(feature_indexes)):\n",
        "            f_idx = feature_indexes[f]\n",
        "            # classifier error is the sum of image weights where the classifier\n",
        "            # is right\n",
        "            error = sum(map(lambda img_idx: weights[img_idx] if labels[img_idx] != votes[img_idx, f_idx] else 0, range(num_imgs)))\n",
        "            classification_errors[f] = error\n",
        "\n",
        "        # get best feature, i.e. with smallest error\n",
        "        min_error_idx = np.argmin(classification_errors)\n",
        "        best_error = classification_errors[min_error_idx]\n",
        "        best_feature_idx = feature_indexes[min_error_idx]\n",
        "\n",
        "        # set feature weight\n",
        "        best_feature = features[best_feature_idx]\n",
        "        feature_weight = 0.5 * np.log((1 - best_error) / best_error)\n",
        "        best_feature.weight = feature_weight\n",
        "\n",
        "        classifiers.append(best_feature)\n",
        "\n",
        "        # update image weights\n",
        "        weights = np.array(list(map(lambda img_idx: weights[img_idx] * np.sqrt((1-best_error)/best_error) if labels[img_idx] != votes[img_idx, best_feature_idx] else weights[img_idx] * np.sqrt(best_error/(1-best_error)), range(num_imgs))))\n",
        "\n",
        "        # remove feature (a feature can't be selected twice)\n",
        "        feature_indexes.remove(best_feature_idx)\n",
        "\n",
        "    print('\\tTime needed for Selecting Classifiers:', time.time()-t0,'\\n')\n",
        "\n",
        "    return classifiers\n",
        "\n",
        "\n",
        "def _get_feature_vote(feature, image):\n",
        "    return feature.get_vote(image)\n",
        "\n",
        "\n",
        "def _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height):\n",
        "    print('Creating Haar-like features..')\n",
        "    t0 = time.time()\n",
        "    features = []\n",
        "    for feature in FeatureTypes:\n",
        "        # FeatureTypes are just tuples\n",
        "        feature_start_width = max(min_feature_width, feature[0])\n",
        "        for feature_width in range(feature_start_width, max_feature_width, feature[0]):\n",
        "            feature_start_height = max(min_feature_height, feature[1])\n",
        "            for feature_height in range(feature_start_height, max_feature_height, feature[1]):\n",
        "\n",
        "                ########################\n",
        "                ### FILL IN HERE\n",
        "                ########################\n",
        "                pass # remove this pass\n",
        "\n",
        "                # Loop over possible x values and y values \n",
        "                # - For each (x,y) create the HarrLikeFeature objects.\n",
        "                # - append the HaarlikeFeatures in the features list.\n",
        "            \n",
        "    print('\\t' + str(len(features)) + ' features created.')\n",
        "    print('\\tTime needed for calculating Haar-like features:', time.time()-t0)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHuYBeQyxYGs"
      },
      "source": [
        "### Exercise #5\n",
        "\n",
        "*   Use the learn method to learn a list of two classifiers with the train data. With the learn function you can build a list of classifiers that detect whether an image contains a face or not.\n",
        "\n",
        "*   Use the following hyperparameters of the features and num_classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqnJpKbty91Z"
      },
      "source": [
        "num_classifiers = 2\n",
        "min_feature_height = 8\n",
        "max_feature_height = 10\n",
        "min_feature_width = 8\n",
        "max_feature_width = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OTwWIizy_1T"
      },
      "source": [
        "# solution\n",
        "\n",
        "%%time \n",
        "\n",
        "#classifiers = learn(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOSfL5GezGux"
      },
      "source": [
        "### Exercise #6\n",
        "\n",
        "*   Make a function for voting with different classifiers\n",
        "*   Build two functions ensemble_vote and ensemble_vote_all.\n",
        "*   **ensemble_vote(int_img, classifiers)** has to return a 1 if the majority of the votes of the classifiers is positive and a zero otherwise\n",
        "*   **ensemble_vote_all(int_imgs, classifiers)** has to loop over the list int_imgs and compute the ensemble_vote for each image in the list. It has to return a list containing all the votes for all the images in int_imgs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8ITkNPI1vo9"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgn_vG0e1aFs"
      },
      "source": [
        "*   Use the functions to compute the train and test acurracies for faces and non faces.\n",
        "*   Print the results in the following format:\n",
        "\n",
        "```\n",
        "train results:\n",
        "Correctly identified Faces: 2129/2429  (87.64923836969946%)\n",
        "Correctly identified non-Faces: 4276/8548  (50.02339728591484%)\n",
        "\n",
        "test results:\n",
        "Correctly identified Faces: 300/472  (63.559322033898304%)\n",
        "Correctly identified non-Faces: 74/128  (57.8125%)\n",
        "```\n",
        "\n",
        "*   It is not required to get this exact results but print the information in this format. It facilitates understanding the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eCiAycJ1yCT"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzNiYc-g13n_"
      },
      "source": [
        "### Exercise #7\n",
        "\n",
        "*   Make another test with 20 classifiers instead of 2.\n",
        "*   Inspect the classification results if you use adaboost with 20 classifiers. *   Use the same hyperameters for the features. Print the results as in the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYbr5B7Q14yM"
      },
      "source": [
        "num_classifiers = 20\n",
        "min_feature_height = 8\n",
        "max_feature_height = 10\n",
        "min_feature_width = 8\n",
        "max_feature_width = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4n9iv_T16_n"
      },
      "source": [
        "# solution\n",
        "\n",
        "%%time \n",
        "\n",
        "#classifiers_20 = learn(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx7pAdkt2Las"
      },
      "source": [
        "*   Discuss if the classification results improved in the train data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIDiUnYy2Sd_"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVRDrIVq2Uqc"
      },
      "source": [
        "### Exercise #8\n",
        "\n",
        "*   Change the voting functions so that you can set a threshold for deciding a prediction.\n",
        "*   The threshold value indicates the minimum score for assigning a \"positive\" label (detect a face).\n",
        "*   Create the following functions\n",
        "    *   ensemble_vote_t: returns the final decision of a list of classifiers for a given threshold.\n",
        "    *   ensemble_vote_all_t: Iterates over a list of integral images and returns the final decision of a list of classifiers for each of the images (for a given threshold)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVKa6Ou12jo9"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xurLySYg2kIL"
      },
      "source": [
        "*   Using the list of 20 classifiers compute the following:\n",
        "\n",
        "    1.   number of correct faces over all faces (in the train data)\n",
        "    2.   number of correct non faces over all non faces (in the train data)\n",
        "    3.   number of correct faces over all faces (in the test data)\n",
        "    4.   number of correct non faces over all non faces (in the test data)\n",
        "\n",
        "*   The quantities have to be computed for each of the following thresholds:\n",
        "```\n",
        "thresholds = np.array([x for x in range(-5,5,1)])/10.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdzWEiPc3FDd"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg8-nXwc3GCu"
      },
      "source": [
        "*   Make a bar plot for 1-4. In the x axis write the threshold value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guWtTfnN3NwQ"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed954GYs3IwK"
      },
      "source": [
        "*   Discuss what happens when you increase the threshold value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0o_rbZ5bl42"
      },
      "source": [
        "# Face Recognition using PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAayTY19blQt"
      },
      "source": [
        "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
        "\n",
        "from time import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nERZ0O4UVxcB"
      },
      "source": [
        "*   Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm9ASG8Cbt8S"
      },
      "source": [
        "# Download the data, if not already on disk and load it as numpy arrays\n",
        "\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "# introspect the images arrays to find the shapes\n",
        "n_samples, h, w = lfw_people.images.shape\n",
        "\n",
        "# for machine learning we use the 2 data directly (as relative pixel\n",
        "# positions info is ignored by this model)\n",
        "X = lfw_people.data\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# the label to predict is the id of the person\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "n_classes = target_names.shape[0]\n",
        "\n",
        "print(\"Total dataset size:\")\n",
        "print(\"n_samples: %d\" % n_samples)\n",
        "print(\"n_features: %d\" % n_features)\n",
        "print(\"n_classes: %d\" % n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F0uLOBYV064"
      },
      "source": [
        "*   Creating training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZDOq5L9byIc"
      },
      "source": [
        "# split into a training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "print('Train data shape:', X_train.shape)\n",
        "print('Test data shape:', X_test.shape)\n",
        "print('Number of classes in Train set:', np.unique(y_train).shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMxf0qqgV884"
      },
      "source": [
        "### Exercise #1: PCA Computation\n",
        "*   Compute a PCA (eigenfaces) on the face dataset\n",
        "    *   *Set* number of components to 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fk3-1LWb0NM"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNKh2ENIw-Er"
      },
      "source": [
        "*   Reshape the components output of pca to obtain the eigen faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sg-LFp0xNfj"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-vVnAknxTMr"
      },
      "source": [
        "*   Project the training and testing faces data on the orthonormal basis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCxUQ13FscJN"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QUnMNiXx_a_"
      },
      "source": [
        "*   Plot the most significative eigenfaces (Show the top 12 eigenfaces) as a matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhRvTppZs0I1"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGE2CDmeprup"
      },
      "source": [
        "*   Show the total percentage of variance explained by the selected components of the PCA.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iun4uPF7MVIj"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmmCKAv52xxo"
      },
      "source": [
        "*   What are the shortcomings of PCA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9gVxCuS230e"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ggw9mNLksIP"
      },
      "source": [
        "### Exercise #2: k-NN Classification\n",
        "\n",
        "*   Train a k-nearest neighbor model with the eigenfaces using the default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0_Q7bEJb2Rk"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgCFhdnljlN"
      },
      "source": [
        "*   Predict the test data using the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWpJTUmFb39U"
      },
      "source": [
        "# Quantitative evaluation of the model quality on the test set\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prk7DAVglthc"
      },
      "source": [
        "### Exercise #3: Quantitative results\n",
        "\n",
        "*   Compute accuracy, classification report and confusion matrix of the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgWoxEbEge1H"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "400D8Q50ssMu"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxqArN9st78"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA7zSojX0Qit"
      },
      "source": [
        "*   Explain the measures showed in the classification report.\n",
        "*   Discuss the obtained classification results, both the quantitative as well as the qualitative results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAkZUb370TlZ"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKx5nTPhzeI1"
      },
      "source": [
        "### Exercise #4\n",
        "\n",
        "*   How is the optimal value of 'k' found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzU6y9kKzlq3"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce45YY2z4f4A"
      },
      "source": [
        "*   Use GridSearch to find the optimal value of 'k'.\n",
        "    *   *Hint: GridSearchCV is available in sklearn.model_selection*\n",
        "*   What is the accuracy of the best estimator?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge-VPK1U4yGD"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFsb6Hgpl6t4"
      },
      "source": [
        "### Exercise #5: Qualitative evaluation\n",
        "\n",
        "*   Plot some of the prediction images using matplotlib subplots (4 x 4). Show the true label and predicted label as the title of each sub plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v3p-cffb6Pb"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzBM0cRZ2_nN"
      },
      "source": [
        "*   What are the disadvantages of using kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGzVaVwD3E8i"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MjirnTw--8r"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# **End of L3_1: Face Detection and Recognition**\n",
        "Deadline for L3_1 submission in CampusVirtual is: **Thursday, the 10th of November, 2022**"
      ]
    }
  ]
}