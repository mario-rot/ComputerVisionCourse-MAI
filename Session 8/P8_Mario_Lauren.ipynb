{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mario-rot/ComputerVisionCourse-MAI/blob/main/Session%208/P8_Mario_Lauren.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4rCKcndPybL"
      },
      "source": [
        "# Laboratory #4_1 : Image Classification using CNN\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Creating deep networks using Keras\n",
        "*   Steps necessary in training a neural network\n",
        "*   Prediction and performance analysis using neural networks\n",
        "*   Using pre-trained networks\n",
        "*   Feature visualizations\n",
        "\n",
        "**Remember this is a graded exercise.**\n",
        "\n",
        "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
        "*   Create reusable functions where ever possible, so that the code could be reused at different places.\n",
        "*   Mount your drive to access the images.\n",
        "*   Add sufficient comments and explanations wherever necessary.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdglSzOi4Cp-"
      },
      "source": [
        "# **Colaboratory environment**\n",
        "By default, Colab notebooks run on CPU.\n",
        "You can switch your notebook to run with GPU.\n",
        "\n",
        "In order to obtain access to the GPU, you need to choose the tab Runtime and then select “Change runtime type” as shown in the following figure:\n",
        "\n",
        "![Changing runtime](https://miro.medium.com/max/747/1*euE7nGZ0uJQcgvkpgvkoQg.png)\n",
        "\n",
        "When a pop-up window appears select GPU. Ensure “Hardware accelerator” is set to GPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "xCVuDt_K5vnq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git clone https://github.com/mario-rot/ComputerVisionCourse-MAI.git\n",
        "cd 'ComputerVisionCourse-MAI'\n",
        "mv 'customplots.py' /content/\n",
        "mv 'utils.py' /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-a_mu5450ve",
        "outputId": "64fd0a93-724b-4a5f-fc3d-f6ce629da783"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ComputerVisionCourse-MAI'...\n",
            "remote: Enumerating objects: 12205, done.\u001b[K\n",
            "remote: Counting objects: 100% (626/626), done.\u001b[K\n",
            "remote: Compressing objects: 100% (495/495), done.\u001b[K\n",
            "remote: Total 12205 (delta 158), reused 560 (delta 119), pack-reused 11579\u001b[K\n",
            "Receiving objects: 100% (12205/12205), 80.98 MiB | 17.79 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "Checking out files: 100% (11915/11915), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from skimage.feature import ORB\n",
        "from skimage import feature\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread, imread_collection\n",
        "from scipy.cluster.vq import vq\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils import get_multi_ORB\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import collections\n",
        "import skimage.exposure as ske\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from customplots import plot_confusion_matrix, custom_grids"
      ],
      "metadata": {
        "id": "g5q4cQE66AE4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkicuxZdrdq"
      },
      "source": [
        "# **Working with a new dataset: CIFAR-10**\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. More information about CIFAR-10 can be found [here](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "In Keras, the CIFAR-10 dataset is also preloaded in the form of four Numpy arrays. x_train and y_train contain the training set, while x_test and y_test contain the test data. The images are encoded as Numpy arrays and their corresponding labels ranging from 0 to 9.\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "*   Visualize the images in CIFAR-10 dataset. Create a 10 x 10 plot showing 10 random samples from each class.\n",
        "*   Convert the labels to one-hot encoded form.\n",
        "*   Normalize the images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrb20KGMtTFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43dfc878-d835-40ae-9536-19e8a6cee87c"
      },
      "source": [
        "# solution\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "counters = [10]*10\n",
        "images = {i:[] for i in range(10)}\n",
        "\n",
        "for idx, i in enumerate(y_train):\n",
        "  if counters[i[0]] != 0:\n",
        "    counters[i[0]] -= 1\n",
        "    images[i[0]].append(x_train[idx])\n",
        "  if sum(counters) == 0:\n",
        "    break\n",
        "\n",
        "images = [img for sublist in list(images.values()) for img in sublist]\n",
        "\n",
        "custom_grids(images[0:100], 10, 10, figsize = (15,20), axis='off', use_grid_spec=False).show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ER5WlMNRydp"
      },
      "source": [
        "## Define the following model (same as the one in tutorial)\n",
        "\n",
        "**For the convolutional front-end, start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. Use the input as (32,32,3). The filter maps can then be flattened to provide features to the classifier. Use a dense layer with 100 units before the classification layer (which is also a dense layer with softmax activation).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfWCHxh8HGhN"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSN6riPISBMG"
      },
      "source": [
        "# solution\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtivbQJT39U"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 512 epochs with a batch size of 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn8UzPBZugVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0e43ec-2be0-4c09-fe48-006f6047997d"
      },
      "source": [
        "# solution\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_train.ndim)\n",
        "print(x_train.dtype)\n",
        "print(x_test.shape)\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "print('After reshaping:')\n",
        "\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_train.ndim)\n",
        "print(x_train.dtype)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "history = model.fit(x_train, y_train_cat, batch_size=32, epochs=512, validation_split=0.1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "4\n",
            "float32\n",
            "(10000, 32, 32, 3)\n",
            "After reshaping:\n",
            "(50000, 32, 32, 3)\n",
            "4\n",
            "float32\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n",
            "Epoch 1/512\n",
            "1407/1407 [==============================] - 15s 5ms/step - loss: 2.3020 - accuracy: 0.1096 - val_loss: 2.3017 - val_accuracy: 0.1004\n",
            "Epoch 2/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.3014 - accuracy: 0.1116 - val_loss: 2.3012 - val_accuracy: 0.0976\n",
            "Epoch 3/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.3008 - accuracy: 0.1129 - val_loss: 2.3002 - val_accuracy: 0.1182\n",
            "Epoch 4/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.3000 - accuracy: 0.1169 - val_loss: 2.2997 - val_accuracy: 0.1498\n",
            "Epoch 5/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2994 - accuracy: 0.1120 - val_loss: 2.2988 - val_accuracy: 0.1284\n",
            "Epoch 6/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.2983 - accuracy: 0.1222 - val_loss: 2.2974 - val_accuracy: 0.1426\n",
            "Epoch 7/512\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 2.2972 - accuracy: 0.1264 - val_loss: 2.2956 - val_accuracy: 0.1504\n",
            "Epoch 8/512\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 2.2957 - accuracy: 0.1248 - val_loss: 2.2941 - val_accuracy: 0.1224\n",
            "Epoch 9/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2938 - accuracy: 0.1281 - val_loss: 2.2977 - val_accuracy: 0.0992\n",
            "Epoch 10/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2916 - accuracy: 0.1316 - val_loss: 2.2898 - val_accuracy: 0.1516\n",
            "Epoch 11/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2890 - accuracy: 0.1340 - val_loss: 2.2993 - val_accuracy: 0.0976\n",
            "Epoch 12/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2858 - accuracy: 0.1433 - val_loss: 2.2970 - val_accuracy: 0.0978\n",
            "Epoch 13/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2818 - accuracy: 0.1469 - val_loss: 2.2755 - val_accuracy: 0.1978\n",
            "Epoch 14/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2765 - accuracy: 0.1535 - val_loss: 2.2847 - val_accuracy: 0.1130\n",
            "Epoch 15/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2705 - accuracy: 0.1572 - val_loss: 2.2597 - val_accuracy: 0.1958\n",
            "Epoch 16/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2618 - accuracy: 0.1661 - val_loss: 2.2525 - val_accuracy: 0.1602\n",
            "Epoch 17/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2516 - accuracy: 0.1767 - val_loss: 2.3260 - val_accuracy: 0.1004\n",
            "Epoch 18/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2388 - accuracy: 0.1830 - val_loss: 2.2207 - val_accuracy: 0.2304\n",
            "Epoch 19/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2250 - accuracy: 0.1875 - val_loss: 2.2098 - val_accuracy: 0.1998\n",
            "Epoch 20/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.2078 - accuracy: 0.1978 - val_loss: 2.1906 - val_accuracy: 0.2300\n",
            "Epoch 21/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1930 - accuracy: 0.1988 - val_loss: 2.1764 - val_accuracy: 0.2210\n",
            "Epoch 22/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1803 - accuracy: 0.2046 - val_loss: 2.1671 - val_accuracy: 0.2048\n",
            "Epoch 23/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1697 - accuracy: 0.2084 - val_loss: 2.1717 - val_accuracy: 0.1778\n",
            "Epoch 24/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1593 - accuracy: 0.2094 - val_loss: 2.3146 - val_accuracy: 0.1148\n",
            "Epoch 25/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.1530 - accuracy: 0.2100 - val_loss: 2.2029 - val_accuracy: 0.1674\n",
            "Epoch 26/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1469 - accuracy: 0.2128 - val_loss: 2.1310 - val_accuracy: 0.2416\n",
            "Epoch 27/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1391 - accuracy: 0.2171 - val_loss: 2.1362 - val_accuracy: 0.2176\n",
            "Epoch 28/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1325 - accuracy: 0.2230 - val_loss: 2.2610 - val_accuracy: 0.1508\n",
            "Epoch 29/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1264 - accuracy: 0.2288 - val_loss: 2.1116 - val_accuracy: 0.2400\n",
            "Epoch 30/512\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 2.1211 - accuracy: 0.2299 - val_loss: 2.1418 - val_accuracy: 0.2022\n",
            "Epoch 31/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1137 - accuracy: 0.2341 - val_loss: 2.1536 - val_accuracy: 0.1848\n",
            "Epoch 32/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1075 - accuracy: 0.2380 - val_loss: 2.1476 - val_accuracy: 0.1940\n",
            "Epoch 33/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.1001 - accuracy: 0.2445 - val_loss: 2.4233 - val_accuracy: 0.1300\n",
            "Epoch 34/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0945 - accuracy: 0.2461 - val_loss: 2.1327 - val_accuracy: 0.1918\n",
            "Epoch 35/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0862 - accuracy: 0.2483 - val_loss: 2.0736 - val_accuracy: 0.2768\n",
            "Epoch 36/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0791 - accuracy: 0.2534 - val_loss: 2.1645 - val_accuracy: 0.1738\n",
            "Epoch 37/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0727 - accuracy: 0.2555 - val_loss: 2.2180 - val_accuracy: 0.1804\n",
            "Epoch 38/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0662 - accuracy: 0.2583 - val_loss: 2.0931 - val_accuracy: 0.2378\n",
            "Epoch 39/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0578 - accuracy: 0.2663 - val_loss: 2.3589 - val_accuracy: 0.1322\n",
            "Epoch 40/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0527 - accuracy: 0.2678 - val_loss: 2.0760 - val_accuracy: 0.2470\n",
            "Epoch 41/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0446 - accuracy: 0.2727 - val_loss: 2.0405 - val_accuracy: 0.2704\n",
            "Epoch 42/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0388 - accuracy: 0.2732 - val_loss: 2.0347 - val_accuracy: 0.2780\n",
            "Epoch 43/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.0325 - accuracy: 0.2765 - val_loss: 2.0614 - val_accuracy: 0.2514\n",
            "Epoch 44/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0284 - accuracy: 0.2795 - val_loss: 2.0971 - val_accuracy: 0.2432\n",
            "Epoch 45/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0216 - accuracy: 0.2816 - val_loss: 2.1395 - val_accuracy: 0.2138\n",
            "Epoch 46/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0181 - accuracy: 0.2822 - val_loss: 2.1448 - val_accuracy: 0.2162\n",
            "Epoch 47/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0115 - accuracy: 0.2841 - val_loss: 2.0086 - val_accuracy: 0.2890\n",
            "Epoch 48/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0062 - accuracy: 0.2878 - val_loss: 1.9978 - val_accuracy: 0.2972\n",
            "Epoch 49/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 2.0021 - accuracy: 0.2921 - val_loss: 2.0392 - val_accuracy: 0.2530\n",
            "Epoch 50/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9960 - accuracy: 0.2934 - val_loss: 2.0240 - val_accuracy: 0.2626\n",
            "Epoch 51/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9933 - accuracy: 0.2957 - val_loss: 2.0180 - val_accuracy: 0.2912\n",
            "Epoch 52/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9882 - accuracy: 0.2961 - val_loss: 1.9840 - val_accuracy: 0.3044\n",
            "Epoch 53/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9846 - accuracy: 0.2951 - val_loss: 2.2619 - val_accuracy: 0.1826\n",
            "Epoch 54/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9787 - accuracy: 0.3001 - val_loss: 1.9750 - val_accuracy: 0.3060\n",
            "Epoch 55/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9738 - accuracy: 0.3010 - val_loss: 2.0356 - val_accuracy: 0.2470\n",
            "Epoch 56/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9694 - accuracy: 0.3034 - val_loss: 1.9662 - val_accuracy: 0.3122\n",
            "Epoch 57/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9620 - accuracy: 0.3046 - val_loss: 1.9812 - val_accuracy: 0.2962\n",
            "Epoch 58/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9589 - accuracy: 0.3080 - val_loss: 2.0979 - val_accuracy: 0.2380\n",
            "Epoch 59/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9545 - accuracy: 0.3088 - val_loss: 2.1682 - val_accuracy: 0.2208\n",
            "Epoch 60/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9508 - accuracy: 0.3107 - val_loss: 1.9455 - val_accuracy: 0.3126\n",
            "Epoch 61/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9434 - accuracy: 0.3128 - val_loss: 1.9712 - val_accuracy: 0.2976\n",
            "Epoch 62/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9388 - accuracy: 0.3131 - val_loss: 1.9396 - val_accuracy: 0.3246\n",
            "Epoch 63/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9344 - accuracy: 0.3179 - val_loss: 1.9498 - val_accuracy: 0.3044\n",
            "Epoch 64/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9275 - accuracy: 0.3201 - val_loss: 1.9387 - val_accuracy: 0.3122\n",
            "Epoch 65/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9229 - accuracy: 0.3214 - val_loss: 2.4045 - val_accuracy: 0.1382\n",
            "Epoch 66/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9175 - accuracy: 0.3213 - val_loss: 1.9183 - val_accuracy: 0.3224\n",
            "Epoch 67/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9109 - accuracy: 0.3244 - val_loss: 1.9733 - val_accuracy: 0.2818\n",
            "Epoch 68/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.9050 - accuracy: 0.3246 - val_loss: 2.5512 - val_accuracy: 0.1352\n",
            "Epoch 69/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8998 - accuracy: 0.3294 - val_loss: 1.8946 - val_accuracy: 0.3388\n",
            "Epoch 70/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8929 - accuracy: 0.3296 - val_loss: 1.9027 - val_accuracy: 0.3302\n",
            "Epoch 71/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8867 - accuracy: 0.3333 - val_loss: 1.8867 - val_accuracy: 0.3366\n",
            "Epoch 72/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8798 - accuracy: 0.3348 - val_loss: 1.9036 - val_accuracy: 0.3274\n",
            "Epoch 73/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8729 - accuracy: 0.3376 - val_loss: 1.8999 - val_accuracy: 0.3358\n",
            "Epoch 74/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8695 - accuracy: 0.3390 - val_loss: 2.1865 - val_accuracy: 0.2084\n",
            "Epoch 75/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8630 - accuracy: 0.3410 - val_loss: 1.8700 - val_accuracy: 0.3390\n",
            "Epoch 76/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8570 - accuracy: 0.3438 - val_loss: 1.8712 - val_accuracy: 0.3376\n",
            "Epoch 77/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8501 - accuracy: 0.3467 - val_loss: 1.8460 - val_accuracy: 0.3518\n",
            "Epoch 78/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.8434 - accuracy: 0.3483 - val_loss: 1.8755 - val_accuracy: 0.3324\n",
            "Epoch 79/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8382 - accuracy: 0.3493 - val_loss: 1.8341 - val_accuracy: 0.3602\n",
            "Epoch 80/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8304 - accuracy: 0.3518 - val_loss: 2.1280 - val_accuracy: 0.2172\n",
            "Epoch 81/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8262 - accuracy: 0.3564 - val_loss: 1.8483 - val_accuracy: 0.3500\n",
            "Epoch 82/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8211 - accuracy: 0.3570 - val_loss: 2.0011 - val_accuracy: 0.2734\n",
            "Epoch 83/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8164 - accuracy: 0.3591 - val_loss: 1.8119 - val_accuracy: 0.3720\n",
            "Epoch 84/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8087 - accuracy: 0.3645 - val_loss: 1.9331 - val_accuracy: 0.3020\n",
            "Epoch 85/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8032 - accuracy: 0.3647 - val_loss: 1.8009 - val_accuracy: 0.3746\n",
            "Epoch 86/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7980 - accuracy: 0.3664 - val_loss: 1.8190 - val_accuracy: 0.3556\n",
            "Epoch 87/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.7912 - accuracy: 0.3692 - val_loss: 2.0918 - val_accuracy: 0.2350\n",
            "Epoch 88/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7898 - accuracy: 0.3687 - val_loss: 1.8708 - val_accuracy: 0.3308\n",
            "Epoch 89/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7823 - accuracy: 0.3728 - val_loss: 1.8870 - val_accuracy: 0.3174\n",
            "Epoch 90/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7788 - accuracy: 0.3732 - val_loss: 1.8091 - val_accuracy: 0.3612\n",
            "Epoch 91/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7721 - accuracy: 0.3744 - val_loss: 1.8282 - val_accuracy: 0.3508\n",
            "Epoch 92/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7665 - accuracy: 0.3767 - val_loss: 1.9036 - val_accuracy: 0.3124\n",
            "Epoch 93/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7648 - accuracy: 0.3789 - val_loss: 1.7826 - val_accuracy: 0.3782\n",
            "Epoch 94/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7584 - accuracy: 0.3803 - val_loss: 1.7624 - val_accuracy: 0.3820\n",
            "Epoch 95/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7518 - accuracy: 0.3811 - val_loss: 1.7583 - val_accuracy: 0.3874\n",
            "Epoch 96/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7491 - accuracy: 0.3835 - val_loss: 1.7802 - val_accuracy: 0.3750\n",
            "Epoch 97/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7444 - accuracy: 0.3852 - val_loss: 1.7632 - val_accuracy: 0.3848\n",
            "Epoch 98/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7405 - accuracy: 0.3877 - val_loss: 1.8676 - val_accuracy: 0.3314\n",
            "Epoch 99/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7360 - accuracy: 0.3892 - val_loss: 1.7899 - val_accuracy: 0.3644\n",
            "Epoch 100/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7345 - accuracy: 0.3892 - val_loss: 1.7641 - val_accuracy: 0.3758\n",
            "Epoch 101/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7303 - accuracy: 0.3916 - val_loss: 1.8047 - val_accuracy: 0.3616\n",
            "Epoch 102/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7238 - accuracy: 0.3935 - val_loss: 2.0352 - val_accuracy: 0.2618\n",
            "Epoch 103/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7207 - accuracy: 0.3971 - val_loss: 1.7451 - val_accuracy: 0.3938\n",
            "Epoch 104/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7168 - accuracy: 0.3975 - val_loss: 1.7201 - val_accuracy: 0.4008\n",
            "Epoch 105/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7110 - accuracy: 0.3988 - val_loss: 1.8480 - val_accuracy: 0.3356\n",
            "Epoch 106/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7070 - accuracy: 0.4009 - val_loss: 1.8097 - val_accuracy: 0.3556\n",
            "Epoch 107/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.7041 - accuracy: 0.4033 - val_loss: 1.7788 - val_accuracy: 0.3668\n",
            "Epoch 108/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7025 - accuracy: 0.4029 - val_loss: 1.7480 - val_accuracy: 0.3850\n",
            "Epoch 109/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6944 - accuracy: 0.4040 - val_loss: 1.7288 - val_accuracy: 0.3968\n",
            "Epoch 110/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6925 - accuracy: 0.4068 - val_loss: 1.7162 - val_accuracy: 0.3946\n",
            "Epoch 111/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6877 - accuracy: 0.4091 - val_loss: 1.7513 - val_accuracy: 0.3880\n",
            "Epoch 112/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6858 - accuracy: 0.4093 - val_loss: 1.7627 - val_accuracy: 0.3760\n",
            "Epoch 113/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6831 - accuracy: 0.4106 - val_loss: 1.6839 - val_accuracy: 0.4116\n",
            "Epoch 114/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6784 - accuracy: 0.4121 - val_loss: 1.7044 - val_accuracy: 0.4028\n",
            "Epoch 115/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6737 - accuracy: 0.4138 - val_loss: 1.7092 - val_accuracy: 0.4048\n",
            "Epoch 116/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.6702 - accuracy: 0.4173 - val_loss: 1.6753 - val_accuracy: 0.4146\n",
            "Epoch 117/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6654 - accuracy: 0.4173 - val_loss: 1.7404 - val_accuracy: 0.3866\n",
            "Epoch 118/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6633 - accuracy: 0.4184 - val_loss: 1.6754 - val_accuracy: 0.4120\n",
            "Epoch 119/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.6578 - accuracy: 0.4203 - val_loss: 1.6634 - val_accuracy: 0.4152\n",
            "Epoch 120/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6557 - accuracy: 0.4199 - val_loss: 1.6589 - val_accuracy: 0.4218\n",
            "Epoch 121/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6499 - accuracy: 0.4226 - val_loss: 1.7972 - val_accuracy: 0.3572\n",
            "Epoch 122/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6468 - accuracy: 0.4250 - val_loss: 1.7895 - val_accuracy: 0.3648\n",
            "Epoch 123/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6438 - accuracy: 0.4258 - val_loss: 1.6612 - val_accuracy: 0.4208\n",
            "Epoch 124/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6398 - accuracy: 0.4266 - val_loss: 1.7523 - val_accuracy: 0.3854\n",
            "Epoch 125/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6367 - accuracy: 0.4284 - val_loss: 1.8015 - val_accuracy: 0.3670\n",
            "Epoch 126/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6317 - accuracy: 0.4293 - val_loss: 1.6463 - val_accuracy: 0.4260\n",
            "Epoch 127/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6303 - accuracy: 0.4312 - val_loss: 1.7154 - val_accuracy: 0.3970\n",
            "Epoch 128/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6283 - accuracy: 0.4326 - val_loss: 1.8186 - val_accuracy: 0.3536\n",
            "Epoch 129/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6266 - accuracy: 0.4324 - val_loss: 1.6646 - val_accuracy: 0.4124\n",
            "Epoch 130/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6231 - accuracy: 0.4339 - val_loss: 1.6595 - val_accuracy: 0.4194\n",
            "Epoch 131/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6188 - accuracy: 0.4360 - val_loss: 1.6255 - val_accuracy: 0.4310\n",
            "Epoch 132/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6166 - accuracy: 0.4350 - val_loss: 2.1266 - val_accuracy: 0.2564\n",
            "Epoch 133/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6127 - accuracy: 0.4356 - val_loss: 1.6193 - val_accuracy: 0.4314\n",
            "Epoch 134/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6095 - accuracy: 0.4375 - val_loss: 1.6213 - val_accuracy: 0.4338\n",
            "Epoch 135/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6077 - accuracy: 0.4400 - val_loss: 1.6649 - val_accuracy: 0.4186\n",
            "Epoch 136/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6039 - accuracy: 0.4409 - val_loss: 1.7988 - val_accuracy: 0.3678\n",
            "Epoch 137/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6020 - accuracy: 0.4417 - val_loss: 1.6442 - val_accuracy: 0.4268\n",
            "Epoch 138/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5984 - accuracy: 0.4442 - val_loss: 1.6283 - val_accuracy: 0.4256\n",
            "Epoch 139/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5946 - accuracy: 0.4428 - val_loss: 1.6190 - val_accuracy: 0.4312\n",
            "Epoch 140/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5919 - accuracy: 0.4458 - val_loss: 1.6115 - val_accuracy: 0.4370\n",
            "Epoch 141/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5893 - accuracy: 0.4468 - val_loss: 1.6283 - val_accuracy: 0.4280\n",
            "Epoch 142/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5880 - accuracy: 0.4470 - val_loss: 1.6282 - val_accuracy: 0.4348\n",
            "Epoch 143/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5848 - accuracy: 0.4473 - val_loss: 1.6038 - val_accuracy: 0.4374\n",
            "Epoch 144/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.5829 - accuracy: 0.4474 - val_loss: 1.6127 - val_accuracy: 0.4380\n",
            "Epoch 145/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5809 - accuracy: 0.4498 - val_loss: 1.6283 - val_accuracy: 0.4280\n",
            "Epoch 146/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5761 - accuracy: 0.4523 - val_loss: 1.8570 - val_accuracy: 0.3398\n",
            "Epoch 147/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5742 - accuracy: 0.4511 - val_loss: 1.6135 - val_accuracy: 0.4376\n",
            "Epoch 148/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5720 - accuracy: 0.4537 - val_loss: 1.6409 - val_accuracy: 0.4212\n",
            "Epoch 149/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5697 - accuracy: 0.4523 - val_loss: 1.6167 - val_accuracy: 0.4344\n",
            "Epoch 150/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5690 - accuracy: 0.4543 - val_loss: 1.6361 - val_accuracy: 0.4270\n",
            "Epoch 151/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5655 - accuracy: 0.4545 - val_loss: 1.5906 - val_accuracy: 0.4352\n",
            "Epoch 152/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5621 - accuracy: 0.4560 - val_loss: 1.5876 - val_accuracy: 0.4496\n",
            "Epoch 153/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5599 - accuracy: 0.4567 - val_loss: 1.6858 - val_accuracy: 0.4206\n",
            "Epoch 154/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5576 - accuracy: 0.4554 - val_loss: 1.6098 - val_accuracy: 0.4410\n",
            "Epoch 155/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5558 - accuracy: 0.4564 - val_loss: 1.7348 - val_accuracy: 0.4002\n",
            "Epoch 156/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5536 - accuracy: 0.4599 - val_loss: 1.5731 - val_accuracy: 0.4490\n",
            "Epoch 157/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5525 - accuracy: 0.4594 - val_loss: 1.6965 - val_accuracy: 0.4050\n",
            "Epoch 158/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5489 - accuracy: 0.4604 - val_loss: 1.6339 - val_accuracy: 0.4238\n",
            "Epoch 159/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5476 - accuracy: 0.4601 - val_loss: 1.5640 - val_accuracy: 0.4520\n",
            "Epoch 160/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5446 - accuracy: 0.4605 - val_loss: 1.6516 - val_accuracy: 0.4186\n",
            "Epoch 161/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5428 - accuracy: 0.4618 - val_loss: 1.7912 - val_accuracy: 0.3608\n",
            "Epoch 162/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5405 - accuracy: 0.4635 - val_loss: 1.5616 - val_accuracy: 0.4594\n",
            "Epoch 163/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5376 - accuracy: 0.4648 - val_loss: 1.7302 - val_accuracy: 0.3940\n",
            "Epoch 164/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5362 - accuracy: 0.4653 - val_loss: 1.5909 - val_accuracy: 0.4480\n",
            "Epoch 165/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5330 - accuracy: 0.4643 - val_loss: 1.6277 - val_accuracy: 0.4258\n",
            "Epoch 166/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5317 - accuracy: 0.4665 - val_loss: 1.5854 - val_accuracy: 0.4516\n",
            "Epoch 167/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5303 - accuracy: 0.4699 - val_loss: 1.5525 - val_accuracy: 0.4612\n",
            "Epoch 168/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5276 - accuracy: 0.4670 - val_loss: 1.6891 - val_accuracy: 0.4060\n",
            "Epoch 169/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5275 - accuracy: 0.4661 - val_loss: 1.5626 - val_accuracy: 0.4520\n",
            "Epoch 170/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5228 - accuracy: 0.4671 - val_loss: 1.5733 - val_accuracy: 0.4504\n",
            "Epoch 171/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5213 - accuracy: 0.4688 - val_loss: 1.5591 - val_accuracy: 0.4470\n",
            "Epoch 172/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5176 - accuracy: 0.4704 - val_loss: 1.6297 - val_accuracy: 0.4230\n",
            "Epoch 173/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5182 - accuracy: 0.4705 - val_loss: 1.6184 - val_accuracy: 0.4326\n",
            "Epoch 174/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5154 - accuracy: 0.4715 - val_loss: 1.5797 - val_accuracy: 0.4392\n",
            "Epoch 175/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5127 - accuracy: 0.4736 - val_loss: 1.5858 - val_accuracy: 0.4444\n",
            "Epoch 176/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5123 - accuracy: 0.4723 - val_loss: 1.5346 - val_accuracy: 0.4700\n",
            "Epoch 177/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5099 - accuracy: 0.4742 - val_loss: 1.6064 - val_accuracy: 0.4368\n",
            "Epoch 178/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5091 - accuracy: 0.4763 - val_loss: 1.5950 - val_accuracy: 0.4316\n",
            "Epoch 179/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5064 - accuracy: 0.4743 - val_loss: 1.6106 - val_accuracy: 0.4334\n",
            "Epoch 180/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5046 - accuracy: 0.4750 - val_loss: 1.5607 - val_accuracy: 0.4590\n",
            "Epoch 181/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.5027 - accuracy: 0.4759 - val_loss: 1.5278 - val_accuracy: 0.4614\n",
            "Epoch 182/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5001 - accuracy: 0.4764 - val_loss: 1.5276 - val_accuracy: 0.4664\n",
            "Epoch 183/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4971 - accuracy: 0.4780 - val_loss: 1.5356 - val_accuracy: 0.4628\n",
            "Epoch 184/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4968 - accuracy: 0.4800 - val_loss: 1.5543 - val_accuracy: 0.4504\n",
            "Epoch 185/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4940 - accuracy: 0.4788 - val_loss: 1.6102 - val_accuracy: 0.4292\n",
            "Epoch 186/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4932 - accuracy: 0.4788 - val_loss: 1.7656 - val_accuracy: 0.3748\n",
            "Epoch 187/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4913 - accuracy: 0.4802 - val_loss: 1.5541 - val_accuracy: 0.4562\n",
            "Epoch 188/512\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4902 - accuracy: 0.4806 - val_loss: 1.5382 - val_accuracy: 0.4602\n",
            "Epoch 189/512\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4863 - accuracy: 0.4832 - val_loss: 1.5565 - val_accuracy: 0.4462\n",
            "Epoch 190/512\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4860 - accuracy: 0.4818 - val_loss: 1.5191 - val_accuracy: 0.4760\n",
            "Epoch 191/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4838 - accuracy: 0.4843 - val_loss: 1.5412 - val_accuracy: 0.4584\n",
            "Epoch 192/512\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4829 - accuracy: 0.4809 - val_loss: 1.5786 - val_accuracy: 0.4456\n",
            "Epoch 193/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4791 - accuracy: 0.4850 - val_loss: 1.5098 - val_accuracy: 0.4690\n",
            "Epoch 194/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4795 - accuracy: 0.4863 - val_loss: 1.5581 - val_accuracy: 0.4582\n",
            "Epoch 195/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4797 - accuracy: 0.4864 - val_loss: 1.5981 - val_accuracy: 0.4386\n",
            "Epoch 196/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.4802 - accuracy: 0.4848 - val_loss: 1.5646 - val_accuracy: 0.4584\n",
            "Epoch 197/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4772 - accuracy: 0.4856 - val_loss: 2.0531 - val_accuracy: 0.3064\n",
            "Epoch 198/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4758 - accuracy: 0.4864 - val_loss: 1.5062 - val_accuracy: 0.4702\n",
            "Epoch 199/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4746 - accuracy: 0.4859 - val_loss: 1.5762 - val_accuracy: 0.4578\n",
            "Epoch 200/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4714 - accuracy: 0.4858 - val_loss: 1.5428 - val_accuracy: 0.4682\n",
            "Epoch 201/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4711 - accuracy: 0.4899 - val_loss: 1.5553 - val_accuracy: 0.4546\n",
            "Epoch 202/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4675 - accuracy: 0.4896 - val_loss: 1.5164 - val_accuracy: 0.4718\n",
            "Epoch 203/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4655 - accuracy: 0.4875 - val_loss: 1.6277 - val_accuracy: 0.4396\n",
            "Epoch 204/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4666 - accuracy: 0.4884 - val_loss: 1.5883 - val_accuracy: 0.4484\n",
            "Epoch 205/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4630 - accuracy: 0.4890 - val_loss: 1.6008 - val_accuracy: 0.4440\n",
            "Epoch 206/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4611 - accuracy: 0.4921 - val_loss: 1.5040 - val_accuracy: 0.4758\n",
            "Epoch 207/512\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4609 - accuracy: 0.4909 - val_loss: 1.5201 - val_accuracy: 0.4656\n",
            "Epoch 208/512\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4575 - accuracy: 0.4932 - val_loss: 1.4991 - val_accuracy: 0.4720\n",
            "Epoch 209/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4569 - accuracy: 0.4916 - val_loss: 1.5461 - val_accuracy: 0.4616\n",
            "Epoch 210/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4538 - accuracy: 0.4932 - val_loss: 1.6815 - val_accuracy: 0.4164\n",
            "Epoch 211/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4536 - accuracy: 0.4950 - val_loss: 1.5360 - val_accuracy: 0.4652\n",
            "Epoch 212/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4527 - accuracy: 0.4946 - val_loss: 1.5471 - val_accuracy: 0.4596\n",
            "Epoch 213/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4503 - accuracy: 0.4952 - val_loss: 1.6130 - val_accuracy: 0.4368\n",
            "Epoch 214/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4497 - accuracy: 0.4953 - val_loss: 1.6526 - val_accuracy: 0.4352\n",
            "Epoch 215/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4471 - accuracy: 0.4976 - val_loss: 1.9470 - val_accuracy: 0.3444\n",
            "Epoch 216/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4456 - accuracy: 0.4973 - val_loss: 1.4974 - val_accuracy: 0.4820\n",
            "Epoch 217/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4445 - accuracy: 0.4968 - val_loss: 1.4962 - val_accuracy: 0.4776\n",
            "Epoch 218/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4424 - accuracy: 0.4973 - val_loss: 1.5132 - val_accuracy: 0.4674\n",
            "Epoch 219/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4411 - accuracy: 0.4978 - val_loss: 1.4927 - val_accuracy: 0.4780\n",
            "Epoch 220/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4389 - accuracy: 0.4994 - val_loss: 1.9230 - val_accuracy: 0.3382\n",
            "Epoch 221/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4376 - accuracy: 0.4985 - val_loss: 1.7059 - val_accuracy: 0.4150\n",
            "Epoch 222/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4379 - accuracy: 0.5008 - val_loss: 1.5738 - val_accuracy: 0.4506\n",
            "Epoch 223/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4336 - accuracy: 0.5014 - val_loss: 1.5442 - val_accuracy: 0.4564\n",
            "Epoch 224/512\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4348 - accuracy: 0.4996 - val_loss: 1.5285 - val_accuracy: 0.4726\n",
            "Epoch 225/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.4326 - accuracy: 0.5005 - val_loss: 1.4871 - val_accuracy: 0.4804\n",
            "Epoch 226/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4310 - accuracy: 0.5011 - val_loss: 1.5197 - val_accuracy: 0.4674\n",
            "Epoch 227/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4285 - accuracy: 0.5015 - val_loss: 1.5450 - val_accuracy: 0.4622\n",
            "Epoch 228/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4273 - accuracy: 0.5036 - val_loss: 1.5426 - val_accuracy: 0.4612\n",
            "Epoch 229/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4265 - accuracy: 0.5036 - val_loss: 1.4899 - val_accuracy: 0.4810\n",
            "Epoch 230/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4217 - accuracy: 0.5053 - val_loss: 1.5280 - val_accuracy: 0.4652\n",
            "Epoch 231/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4250 - accuracy: 0.5046 - val_loss: 1.6402 - val_accuracy: 0.4348\n",
            "Epoch 232/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4241 - accuracy: 0.5050 - val_loss: 1.4680 - val_accuracy: 0.4898\n",
            "Epoch 233/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4193 - accuracy: 0.5064 - val_loss: 1.6502 - val_accuracy: 0.4436\n",
            "Epoch 234/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4177 - accuracy: 0.5070 - val_loss: 1.4939 - val_accuracy: 0.4794\n",
            "Epoch 235/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4173 - accuracy: 0.5071 - val_loss: 1.5185 - val_accuracy: 0.4718\n",
            "Epoch 236/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4159 - accuracy: 0.5084 - val_loss: 1.4709 - val_accuracy: 0.4858\n",
            "Epoch 237/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4139 - accuracy: 0.5074 - val_loss: 1.6568 - val_accuracy: 0.4296\n",
            "Epoch 238/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4114 - accuracy: 0.5087 - val_loss: 1.4911 - val_accuracy: 0.4770\n",
            "Epoch 239/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4109 - accuracy: 0.5072 - val_loss: 2.0295 - val_accuracy: 0.3332\n",
            "Epoch 240/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4107 - accuracy: 0.5109 - val_loss: 1.5092 - val_accuracy: 0.4762\n",
            "Epoch 241/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4087 - accuracy: 0.5073 - val_loss: 1.5413 - val_accuracy: 0.4548\n",
            "Epoch 242/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4083 - accuracy: 0.5101 - val_loss: 1.5452 - val_accuracy: 0.4686\n",
            "Epoch 243/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4062 - accuracy: 0.5107 - val_loss: 1.5087 - val_accuracy: 0.4720\n",
            "Epoch 244/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4040 - accuracy: 0.5116 - val_loss: 1.4626 - val_accuracy: 0.4934\n",
            "Epoch 245/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4031 - accuracy: 0.5125 - val_loss: 1.5441 - val_accuracy: 0.4634\n",
            "Epoch 246/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4014 - accuracy: 0.5123 - val_loss: 1.4628 - val_accuracy: 0.4886\n",
            "Epoch 247/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4001 - accuracy: 0.5139 - val_loss: 1.4852 - val_accuracy: 0.4760\n",
            "Epoch 248/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4000 - accuracy: 0.5140 - val_loss: 1.5477 - val_accuracy: 0.4598\n",
            "Epoch 249/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3980 - accuracy: 0.5124 - val_loss: 1.4663 - val_accuracy: 0.4910\n",
            "Epoch 250/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3961 - accuracy: 0.5136 - val_loss: 1.4629 - val_accuracy: 0.4914\n",
            "Epoch 251/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3944 - accuracy: 0.5148 - val_loss: 1.6113 - val_accuracy: 0.4370\n",
            "Epoch 252/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3942 - accuracy: 0.5151 - val_loss: 1.4466 - val_accuracy: 0.4980\n",
            "Epoch 253/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3921 - accuracy: 0.5148 - val_loss: 1.4908 - val_accuracy: 0.4782\n",
            "Epoch 254/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3900 - accuracy: 0.5162 - val_loss: 1.4536 - val_accuracy: 0.4934\n",
            "Epoch 255/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.3892 - accuracy: 0.5175 - val_loss: 1.5466 - val_accuracy: 0.4624\n",
            "Epoch 256/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3871 - accuracy: 0.5164 - val_loss: 1.5275 - val_accuracy: 0.4728\n",
            "Epoch 257/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3871 - accuracy: 0.5171 - val_loss: 1.4720 - val_accuracy: 0.4838\n",
            "Epoch 258/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3848 - accuracy: 0.5190 - val_loss: 1.4324 - val_accuracy: 0.5032\n",
            "Epoch 259/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3842 - accuracy: 0.5182 - val_loss: 1.5468 - val_accuracy: 0.4550\n",
            "Epoch 260/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3817 - accuracy: 0.5184 - val_loss: 1.4764 - val_accuracy: 0.4860\n",
            "Epoch 261/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3817 - accuracy: 0.5187 - val_loss: 1.4598 - val_accuracy: 0.4880\n",
            "Epoch 262/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3792 - accuracy: 0.5219 - val_loss: 1.5315 - val_accuracy: 0.4588\n",
            "Epoch 263/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3775 - accuracy: 0.5202 - val_loss: 1.4930 - val_accuracy: 0.4804\n",
            "Epoch 264/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3751 - accuracy: 0.5213 - val_loss: 1.4811 - val_accuracy: 0.4850\n",
            "Epoch 265/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3744 - accuracy: 0.5228 - val_loss: 1.4670 - val_accuracy: 0.4838\n",
            "Epoch 266/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3725 - accuracy: 0.5226 - val_loss: 1.4388 - val_accuracy: 0.5012\n",
            "Epoch 267/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3717 - accuracy: 0.5238 - val_loss: 1.4384 - val_accuracy: 0.4996\n",
            "Epoch 268/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3715 - accuracy: 0.5242 - val_loss: 1.4616 - val_accuracy: 0.4918\n",
            "Epoch 269/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3711 - accuracy: 0.5234 - val_loss: 1.4496 - val_accuracy: 0.4882\n",
            "Epoch 270/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3674 - accuracy: 0.5239 - val_loss: 1.4344 - val_accuracy: 0.5018\n",
            "Epoch 271/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3674 - accuracy: 0.5249 - val_loss: 1.4908 - val_accuracy: 0.4848\n",
            "Epoch 272/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3661 - accuracy: 0.5227 - val_loss: 1.4477 - val_accuracy: 0.4966\n",
            "Epoch 273/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3640 - accuracy: 0.5267 - val_loss: 1.4974 - val_accuracy: 0.4728\n",
            "Epoch 274/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3656 - accuracy: 0.5233 - val_loss: 1.4600 - val_accuracy: 0.4902\n",
            "Epoch 275/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3769 - accuracy: 0.5204 - val_loss: 1.4404 - val_accuracy: 0.5006\n",
            "Epoch 276/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3712 - accuracy: 0.5228 - val_loss: 1.4624 - val_accuracy: 0.4858\n",
            "Epoch 277/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.3677 - accuracy: 0.5242 - val_loss: 1.4650 - val_accuracy: 0.4776\n",
            "Epoch 278/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3662 - accuracy: 0.5237 - val_loss: 1.4756 - val_accuracy: 0.4852\n",
            "Epoch 279/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3642 - accuracy: 0.5262 - val_loss: 1.4900 - val_accuracy: 0.4816\n",
            "Epoch 280/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3626 - accuracy: 0.5256 - val_loss: 1.4273 - val_accuracy: 0.4998\n",
            "Epoch 281/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3612 - accuracy: 0.5235 - val_loss: 1.4965 - val_accuracy: 0.4796\n",
            "Epoch 282/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3588 - accuracy: 0.5264 - val_loss: 1.4338 - val_accuracy: 0.5020\n",
            "Epoch 283/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3568 - accuracy: 0.5301 - val_loss: 1.4432 - val_accuracy: 0.4974\n",
            "Epoch 284/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3580 - accuracy: 0.5285 - val_loss: 1.4913 - val_accuracy: 0.4814\n",
            "Epoch 285/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3566 - accuracy: 0.5286 - val_loss: 1.4814 - val_accuracy: 0.4920\n",
            "Epoch 286/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3529 - accuracy: 0.5293 - val_loss: 1.4289 - val_accuracy: 0.4984\n",
            "Epoch 287/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3525 - accuracy: 0.5290 - val_loss: 1.4494 - val_accuracy: 0.4998\n",
            "Epoch 288/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3506 - accuracy: 0.5294 - val_loss: 1.5338 - val_accuracy: 0.4744\n",
            "Epoch 289/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3498 - accuracy: 0.5291 - val_loss: 1.7056 - val_accuracy: 0.4142\n",
            "Epoch 290/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3510 - accuracy: 0.5304 - val_loss: 1.4443 - val_accuracy: 0.4986\n",
            "Epoch 291/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3480 - accuracy: 0.5304 - val_loss: 1.4901 - val_accuracy: 0.4784\n",
            "Epoch 292/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3451 - accuracy: 0.5314 - val_loss: 1.4495 - val_accuracy: 0.4944\n",
            "Epoch 293/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3460 - accuracy: 0.5309 - val_loss: 1.4862 - val_accuracy: 0.4866\n",
            "Epoch 294/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3407 - accuracy: 0.5322 - val_loss: 1.4315 - val_accuracy: 0.5038\n",
            "Epoch 295/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3407 - accuracy: 0.5334 - val_loss: 1.4610 - val_accuracy: 0.4960\n",
            "Epoch 296/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3409 - accuracy: 0.5326 - val_loss: 1.4483 - val_accuracy: 0.4848\n",
            "Epoch 297/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3395 - accuracy: 0.5316 - val_loss: 1.4168 - val_accuracy: 0.5056\n",
            "Epoch 298/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3380 - accuracy: 0.5347 - val_loss: 1.7242 - val_accuracy: 0.4142\n",
            "Epoch 299/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3376 - accuracy: 0.5346 - val_loss: 1.4765 - val_accuracy: 0.4874\n",
            "Epoch 300/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3351 - accuracy: 0.5357 - val_loss: 1.4247 - val_accuracy: 0.4998\n",
            "Epoch 301/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3330 - accuracy: 0.5367 - val_loss: 1.4478 - val_accuracy: 0.4976\n",
            "Epoch 302/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3321 - accuracy: 0.5348 - val_loss: 1.4552 - val_accuracy: 0.4994\n",
            "Epoch 303/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3316 - accuracy: 0.5357 - val_loss: 1.4270 - val_accuracy: 0.5028\n",
            "Epoch 304/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3306 - accuracy: 0.5371 - val_loss: 1.4019 - val_accuracy: 0.5064\n",
            "Epoch 305/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3281 - accuracy: 0.5385 - val_loss: 1.4095 - val_accuracy: 0.5104\n",
            "Epoch 306/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3276 - accuracy: 0.5388 - val_loss: 1.6829 - val_accuracy: 0.4306\n",
            "Epoch 307/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3269 - accuracy: 0.5386 - val_loss: 1.5247 - val_accuracy: 0.4696\n",
            "Epoch 308/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3251 - accuracy: 0.5393 - val_loss: 1.6336 - val_accuracy: 0.4378\n",
            "Epoch 309/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3239 - accuracy: 0.5380 - val_loss: 1.5448 - val_accuracy: 0.4632\n",
            "Epoch 310/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3233 - accuracy: 0.5385 - val_loss: 1.5264 - val_accuracy: 0.4760\n",
            "Epoch 311/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3205 - accuracy: 0.5390 - val_loss: 1.4568 - val_accuracy: 0.4972\n",
            "Epoch 312/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3199 - accuracy: 0.5389 - val_loss: 1.6432 - val_accuracy: 0.4296\n",
            "Epoch 313/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3183 - accuracy: 0.5401 - val_loss: 1.4790 - val_accuracy: 0.4906\n",
            "Epoch 314/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.3178 - accuracy: 0.5400 - val_loss: 1.4070 - val_accuracy: 0.5048\n",
            "Epoch 315/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3163 - accuracy: 0.5408 - val_loss: 1.9460 - val_accuracy: 0.3470\n",
            "Epoch 316/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3160 - accuracy: 0.5410 - val_loss: 1.5661 - val_accuracy: 0.4618\n",
            "Epoch 317/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3142 - accuracy: 0.5408 - val_loss: 1.5792 - val_accuracy: 0.4594\n",
            "Epoch 318/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3130 - accuracy: 0.5435 - val_loss: 1.5211 - val_accuracy: 0.4736\n",
            "Epoch 319/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3111 - accuracy: 0.5443 - val_loss: 1.3928 - val_accuracy: 0.5162\n",
            "Epoch 320/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3121 - accuracy: 0.5426 - val_loss: 1.4020 - val_accuracy: 0.5120\n",
            "Epoch 321/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3098 - accuracy: 0.5448 - val_loss: 1.4404 - val_accuracy: 0.5050\n",
            "Epoch 322/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3078 - accuracy: 0.5460 - val_loss: 1.3922 - val_accuracy: 0.5144\n",
            "Epoch 323/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3071 - accuracy: 0.5451 - val_loss: 1.4895 - val_accuracy: 0.4826\n",
            "Epoch 324/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3049 - accuracy: 0.5456 - val_loss: 1.4316 - val_accuracy: 0.5010\n",
            "Epoch 325/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3058 - accuracy: 0.5467 - val_loss: 1.4071 - val_accuracy: 0.5126\n",
            "Epoch 326/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3035 - accuracy: 0.5474 - val_loss: 1.3871 - val_accuracy: 0.5152\n",
            "Epoch 327/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3011 - accuracy: 0.5466 - val_loss: 1.4609 - val_accuracy: 0.4998\n",
            "Epoch 328/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3023 - accuracy: 0.5482 - val_loss: 1.4796 - val_accuracy: 0.4812\n",
            "Epoch 329/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2995 - accuracy: 0.5464 - val_loss: 1.4505 - val_accuracy: 0.5028\n",
            "Epoch 330/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2973 - accuracy: 0.5472 - val_loss: 1.4408 - val_accuracy: 0.5046\n",
            "Epoch 331/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2982 - accuracy: 0.5483 - val_loss: 1.4109 - val_accuracy: 0.5114\n",
            "Epoch 332/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2966 - accuracy: 0.5488 - val_loss: 1.3925 - val_accuracy: 0.5146\n",
            "Epoch 333/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2948 - accuracy: 0.5488 - val_loss: 1.4547 - val_accuracy: 0.4940\n",
            "Epoch 334/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2942 - accuracy: 0.5475 - val_loss: 1.4644 - val_accuracy: 0.4912\n",
            "Epoch 335/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2905 - accuracy: 0.5491 - val_loss: 1.4025 - val_accuracy: 0.5194\n",
            "Epoch 336/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2913 - accuracy: 0.5512 - val_loss: 1.4169 - val_accuracy: 0.5144\n",
            "Epoch 337/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2906 - accuracy: 0.5509 - val_loss: 1.4068 - val_accuracy: 0.5152\n",
            "Epoch 338/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2895 - accuracy: 0.5504 - val_loss: 1.3841 - val_accuracy: 0.5132\n",
            "Epoch 339/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2878 - accuracy: 0.5522 - val_loss: 1.4803 - val_accuracy: 0.4896\n",
            "Epoch 340/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2864 - accuracy: 0.5512 - val_loss: 1.4621 - val_accuracy: 0.4976\n",
            "Epoch 341/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2857 - accuracy: 0.5511 - val_loss: 1.3814 - val_accuracy: 0.5230\n",
            "Epoch 342/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2838 - accuracy: 0.5528 - val_loss: 1.5640 - val_accuracy: 0.4602\n",
            "Epoch 343/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2837 - accuracy: 0.5507 - val_loss: 1.4421 - val_accuracy: 0.5038\n",
            "Epoch 344/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2805 - accuracy: 0.5526 - val_loss: 1.5762 - val_accuracy: 0.4578\n",
            "Epoch 345/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2816 - accuracy: 0.5530 - val_loss: 1.3814 - val_accuracy: 0.5272\n",
            "Epoch 346/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2784 - accuracy: 0.5528 - val_loss: 1.4141 - val_accuracy: 0.5058\n",
            "Epoch 347/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2793 - accuracy: 0.5552 - val_loss: 1.5477 - val_accuracy: 0.4712\n",
            "Epoch 348/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2786 - accuracy: 0.5564 - val_loss: 1.4028 - val_accuracy: 0.5140\n",
            "Epoch 349/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2764 - accuracy: 0.5549 - val_loss: 1.5297 - val_accuracy: 0.4694\n",
            "Epoch 350/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2770 - accuracy: 0.5543 - val_loss: 1.4069 - val_accuracy: 0.5074\n",
            "Epoch 351/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2723 - accuracy: 0.5564 - val_loss: 1.4434 - val_accuracy: 0.4936\n",
            "Epoch 352/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2742 - accuracy: 0.5566 - val_loss: 1.4511 - val_accuracy: 0.4946\n",
            "Epoch 353/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2708 - accuracy: 0.5584 - val_loss: 1.4893 - val_accuracy: 0.4854\n",
            "Epoch 354/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2708 - accuracy: 0.5586 - val_loss: 1.3656 - val_accuracy: 0.5290\n",
            "Epoch 355/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2727 - accuracy: 0.5563 - val_loss: 1.6803 - val_accuracy: 0.4316\n",
            "Epoch 356/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2693 - accuracy: 0.5552 - val_loss: 1.3783 - val_accuracy: 0.5222\n",
            "Epoch 357/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2653 - accuracy: 0.5573 - val_loss: 2.3868 - val_accuracy: 0.2872\n",
            "Epoch 358/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2687 - accuracy: 0.5552 - val_loss: 1.4486 - val_accuracy: 0.4968\n",
            "Epoch 359/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2655 - accuracy: 0.5586 - val_loss: 1.3772 - val_accuracy: 0.5214\n",
            "Epoch 360/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2639 - accuracy: 0.5584 - val_loss: 1.4014 - val_accuracy: 0.5096\n",
            "Epoch 361/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2635 - accuracy: 0.5589 - val_loss: 1.4484 - val_accuracy: 0.5000\n",
            "Epoch 362/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2632 - accuracy: 0.5611 - val_loss: 1.4328 - val_accuracy: 0.4960\n",
            "Epoch 363/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2620 - accuracy: 0.5610 - val_loss: 1.5153 - val_accuracy: 0.4734\n",
            "Epoch 364/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2583 - accuracy: 0.5616 - val_loss: 1.6171 - val_accuracy: 0.4436\n",
            "Epoch 365/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2593 - accuracy: 0.5594 - val_loss: 1.5293 - val_accuracy: 0.4776\n",
            "Epoch 366/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2584 - accuracy: 0.5601 - val_loss: 1.4438 - val_accuracy: 0.5030\n",
            "Epoch 367/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2549 - accuracy: 0.5634 - val_loss: 1.3596 - val_accuracy: 0.5330\n",
            "Epoch 368/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2555 - accuracy: 0.5627 - val_loss: 1.4245 - val_accuracy: 0.5088\n",
            "Epoch 369/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2533 - accuracy: 0.5626 - val_loss: 1.4729 - val_accuracy: 0.4946\n",
            "Epoch 370/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2542 - accuracy: 0.5628 - val_loss: 1.4084 - val_accuracy: 0.5134\n",
            "Epoch 371/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2496 - accuracy: 0.5650 - val_loss: 1.6100 - val_accuracy: 0.4492\n",
            "Epoch 372/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2511 - accuracy: 0.5631 - val_loss: 1.3444 - val_accuracy: 0.5408\n",
            "Epoch 373/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2502 - accuracy: 0.5653 - val_loss: 1.3509 - val_accuracy: 0.5310\n",
            "Epoch 374/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2482 - accuracy: 0.5640 - val_loss: 1.3758 - val_accuracy: 0.5276\n",
            "Epoch 375/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2484 - accuracy: 0.5646 - val_loss: 1.5652 - val_accuracy: 0.4594\n",
            "Epoch 376/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2464 - accuracy: 0.5666 - val_loss: 1.4470 - val_accuracy: 0.4884\n",
            "Epoch 377/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2438 - accuracy: 0.5656 - val_loss: 1.4464 - val_accuracy: 0.5038\n",
            "Epoch 378/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2464 - accuracy: 0.5635 - val_loss: 1.3812 - val_accuracy: 0.5252\n",
            "Epoch 379/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2436 - accuracy: 0.5660 - val_loss: 1.3920 - val_accuracy: 0.5164\n",
            "Epoch 380/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2424 - accuracy: 0.5643 - val_loss: 1.3915 - val_accuracy: 0.5150\n",
            "Epoch 381/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2426 - accuracy: 0.5668 - val_loss: 1.4360 - val_accuracy: 0.5072\n",
            "Epoch 382/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2413 - accuracy: 0.5674 - val_loss: 1.4376 - val_accuracy: 0.5068\n",
            "Epoch 383/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2399 - accuracy: 0.5666 - val_loss: 1.4535 - val_accuracy: 0.4934\n",
            "Epoch 384/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2394 - accuracy: 0.5658 - val_loss: 1.3731 - val_accuracy: 0.5198\n",
            "Epoch 385/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2350 - accuracy: 0.5690 - val_loss: 1.3915 - val_accuracy: 0.5230\n",
            "Epoch 386/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2380 - accuracy: 0.5698 - val_loss: 1.3725 - val_accuracy: 0.5252\n",
            "Epoch 387/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2357 - accuracy: 0.5693 - val_loss: 1.3876 - val_accuracy: 0.5204\n",
            "Epoch 388/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2356 - accuracy: 0.5698 - val_loss: 1.5506 - val_accuracy: 0.4772\n",
            "Epoch 389/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2319 - accuracy: 0.5695 - val_loss: 1.4063 - val_accuracy: 0.5150\n",
            "Epoch 390/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2348 - accuracy: 0.5690 - val_loss: 1.4549 - val_accuracy: 0.4960\n",
            "Epoch 391/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2314 - accuracy: 0.5727 - val_loss: 1.5875 - val_accuracy: 0.4754\n",
            "Epoch 392/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2305 - accuracy: 0.5698 - val_loss: 1.4551 - val_accuracy: 0.5028\n",
            "Epoch 393/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2307 - accuracy: 0.5693 - val_loss: 1.3569 - val_accuracy: 0.5342\n",
            "Epoch 394/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2291 - accuracy: 0.5698 - val_loss: 1.4621 - val_accuracy: 0.4998\n",
            "Epoch 395/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2270 - accuracy: 0.5707 - val_loss: 1.3719 - val_accuracy: 0.5210\n",
            "Epoch 396/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2248 - accuracy: 0.5711 - val_loss: 1.3347 - val_accuracy: 0.5410\n",
            "Epoch 397/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2257 - accuracy: 0.5714 - val_loss: 1.3663 - val_accuracy: 0.5328\n",
            "Epoch 398/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2244 - accuracy: 0.5731 - val_loss: 1.4123 - val_accuracy: 0.5120\n",
            "Epoch 399/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2226 - accuracy: 0.5754 - val_loss: 1.5689 - val_accuracy: 0.4696\n",
            "Epoch 400/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2214 - accuracy: 0.5735 - val_loss: 1.3685 - val_accuracy: 0.5252\n",
            "Epoch 401/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2218 - accuracy: 0.5749 - val_loss: 1.6950 - val_accuracy: 0.4442\n",
            "Epoch 402/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2194 - accuracy: 0.5735 - val_loss: 1.4016 - val_accuracy: 0.5166\n",
            "Epoch 403/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2216 - accuracy: 0.5721 - val_loss: 1.3367 - val_accuracy: 0.5420\n",
            "Epoch 404/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2168 - accuracy: 0.5753 - val_loss: 1.3983 - val_accuracy: 0.5218\n",
            "Epoch 405/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2164 - accuracy: 0.5760 - val_loss: 1.4116 - val_accuracy: 0.5128\n",
            "Epoch 406/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2172 - accuracy: 0.5752 - val_loss: 1.4736 - val_accuracy: 0.4970\n",
            "Epoch 407/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2167 - accuracy: 0.5773 - val_loss: 1.3603 - val_accuracy: 0.5280\n",
            "Epoch 408/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2142 - accuracy: 0.5773 - val_loss: 1.3651 - val_accuracy: 0.5266\n",
            "Epoch 409/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2149 - accuracy: 0.5761 - val_loss: 1.4678 - val_accuracy: 0.4918\n",
            "Epoch 410/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2113 - accuracy: 0.5768 - val_loss: 1.8630 - val_accuracy: 0.4058\n",
            "Epoch 411/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2137 - accuracy: 0.5761 - val_loss: 1.3700 - val_accuracy: 0.5272\n",
            "Epoch 412/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2109 - accuracy: 0.5782 - val_loss: 1.3603 - val_accuracy: 0.5300\n",
            "Epoch 413/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2078 - accuracy: 0.5787 - val_loss: 1.3500 - val_accuracy: 0.5338\n",
            "Epoch 414/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2084 - accuracy: 0.5779 - val_loss: 1.3875 - val_accuracy: 0.5238\n",
            "Epoch 415/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2068 - accuracy: 0.5799 - val_loss: 1.3920 - val_accuracy: 0.5162\n",
            "Epoch 416/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2061 - accuracy: 0.5784 - val_loss: 1.4344 - val_accuracy: 0.5084\n",
            "Epoch 417/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2055 - accuracy: 0.5791 - val_loss: 1.4223 - val_accuracy: 0.5100\n",
            "Epoch 418/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2033 - accuracy: 0.5778 - val_loss: 1.4531 - val_accuracy: 0.5068\n",
            "Epoch 419/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2022 - accuracy: 0.5792 - val_loss: 1.3685 - val_accuracy: 0.5258\n",
            "Epoch 420/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2001 - accuracy: 0.5800 - val_loss: 1.3295 - val_accuracy: 0.5426\n",
            "Epoch 421/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1987 - accuracy: 0.5830 - val_loss: 1.3693 - val_accuracy: 0.5230\n",
            "Epoch 422/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1999 - accuracy: 0.5818 - val_loss: 1.4089 - val_accuracy: 0.5158\n",
            "Epoch 423/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2020 - accuracy: 0.5817 - val_loss: 1.3707 - val_accuracy: 0.5260\n",
            "Epoch 424/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1988 - accuracy: 0.5822 - val_loss: 1.5614 - val_accuracy: 0.4738\n",
            "Epoch 425/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2000 - accuracy: 0.5814 - val_loss: 1.4192 - val_accuracy: 0.5154\n",
            "Epoch 426/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1966 - accuracy: 0.5815 - val_loss: 1.5695 - val_accuracy: 0.4704\n",
            "Epoch 427/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1967 - accuracy: 0.5806 - val_loss: 1.4526 - val_accuracy: 0.5048\n",
            "Epoch 428/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1952 - accuracy: 0.5825 - val_loss: 1.3251 - val_accuracy: 0.5430\n",
            "Epoch 429/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1917 - accuracy: 0.5841 - val_loss: 1.3313 - val_accuracy: 0.5434\n",
            "Epoch 430/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1931 - accuracy: 0.5824 - val_loss: 1.6944 - val_accuracy: 0.4464\n",
            "Epoch 431/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1923 - accuracy: 0.5836 - val_loss: 1.4554 - val_accuracy: 0.4992\n",
            "Epoch 432/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1919 - accuracy: 0.5830 - val_loss: 1.7438 - val_accuracy: 0.4214\n",
            "Epoch 433/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1895 - accuracy: 0.5865 - val_loss: 1.3494 - val_accuracy: 0.5318\n",
            "Epoch 434/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1895 - accuracy: 0.5852 - val_loss: 1.3861 - val_accuracy: 0.5192\n",
            "Epoch 435/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1873 - accuracy: 0.5850 - val_loss: 1.4192 - val_accuracy: 0.5110\n",
            "Epoch 436/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1885 - accuracy: 0.5840 - val_loss: 1.3494 - val_accuracy: 0.5324\n",
            "Epoch 437/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1841 - accuracy: 0.5881 - val_loss: 1.5358 - val_accuracy: 0.4720\n",
            "Epoch 438/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1846 - accuracy: 0.5860 - val_loss: 1.3755 - val_accuracy: 0.5286\n",
            "Epoch 439/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1834 - accuracy: 0.5875 - val_loss: 1.3610 - val_accuracy: 0.5256\n",
            "Epoch 440/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1826 - accuracy: 0.5882 - val_loss: 1.5658 - val_accuracy: 0.4712\n",
            "Epoch 441/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1806 - accuracy: 0.5886 - val_loss: 1.3953 - val_accuracy: 0.5266\n",
            "Epoch 442/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1810 - accuracy: 0.5868 - val_loss: 1.3874 - val_accuracy: 0.5232\n",
            "Epoch 443/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1785 - accuracy: 0.5879 - val_loss: 1.3430 - val_accuracy: 0.5410\n",
            "Epoch 444/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1786 - accuracy: 0.5887 - val_loss: 1.3374 - val_accuracy: 0.5350\n",
            "Epoch 445/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1784 - accuracy: 0.5906 - val_loss: 1.5482 - val_accuracy: 0.4676\n",
            "Epoch 446/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1765 - accuracy: 0.5866 - val_loss: 1.3450 - val_accuracy: 0.5358\n",
            "Epoch 447/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1744 - accuracy: 0.5891 - val_loss: 1.4061 - val_accuracy: 0.5154\n",
            "Epoch 448/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1773 - accuracy: 0.5885 - val_loss: 1.3718 - val_accuracy: 0.5328\n",
            "Epoch 449/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1739 - accuracy: 0.5896 - val_loss: 1.3815 - val_accuracy: 0.5220\n",
            "Epoch 450/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1721 - accuracy: 0.5911 - val_loss: 1.6236 - val_accuracy: 0.4596\n",
            "Epoch 451/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1744 - accuracy: 0.5898 - val_loss: 1.3817 - val_accuracy: 0.5222\n",
            "Epoch 452/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1712 - accuracy: 0.5924 - val_loss: 1.3675 - val_accuracy: 0.5308\n",
            "Epoch 453/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1703 - accuracy: 0.5925 - val_loss: 1.4285 - val_accuracy: 0.5144\n",
            "Epoch 454/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1688 - accuracy: 0.5929 - val_loss: 1.5354 - val_accuracy: 0.4854\n",
            "Epoch 455/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1704 - accuracy: 0.5904 - val_loss: 1.4114 - val_accuracy: 0.5152\n",
            "Epoch 456/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1684 - accuracy: 0.5919 - val_loss: 1.3624 - val_accuracy: 0.5276\n",
            "Epoch 457/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1672 - accuracy: 0.5936 - val_loss: 1.4213 - val_accuracy: 0.5136\n",
            "Epoch 458/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1651 - accuracy: 0.5948 - val_loss: 1.3386 - val_accuracy: 0.5398\n",
            "Epoch 459/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1664 - accuracy: 0.5934 - val_loss: 1.3658 - val_accuracy: 0.5274\n",
            "Epoch 460/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1640 - accuracy: 0.5946 - val_loss: 1.4114 - val_accuracy: 0.5138\n",
            "Epoch 461/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1629 - accuracy: 0.5950 - val_loss: 1.4084 - val_accuracy: 0.5200\n",
            "Epoch 462/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1614 - accuracy: 0.5939 - val_loss: 1.4330 - val_accuracy: 0.5088\n",
            "Epoch 463/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1624 - accuracy: 0.5950 - val_loss: 1.6469 - val_accuracy: 0.4516\n",
            "Epoch 464/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1589 - accuracy: 0.5954 - val_loss: 1.5844 - val_accuracy: 0.4664\n",
            "Epoch 465/512\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1593 - accuracy: 0.5966 - val_loss: 1.3823 - val_accuracy: 0.5246\n",
            "Epoch 466/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1566 - accuracy: 0.5977 - val_loss: 1.5865 - val_accuracy: 0.4614\n",
            "Epoch 467/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1565 - accuracy: 0.5947 - val_loss: 1.3950 - val_accuracy: 0.5142\n",
            "Epoch 468/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1554 - accuracy: 0.5976 - val_loss: 1.3225 - val_accuracy: 0.5472\n",
            "Epoch 469/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1560 - accuracy: 0.5956 - val_loss: 1.4716 - val_accuracy: 0.4982\n",
            "Epoch 470/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1554 - accuracy: 0.5951 - val_loss: 1.5321 - val_accuracy: 0.4890\n",
            "Epoch 471/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1531 - accuracy: 0.5972 - val_loss: 1.3545 - val_accuracy: 0.5372\n",
            "Epoch 472/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1538 - accuracy: 0.5962 - val_loss: 1.3906 - val_accuracy: 0.5280\n",
            "Epoch 473/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1538 - accuracy: 0.5980 - val_loss: 1.4486 - val_accuracy: 0.5062\n",
            "Epoch 474/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1499 - accuracy: 0.5983 - val_loss: 1.7148 - val_accuracy: 0.4392\n",
            "Epoch 475/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1506 - accuracy: 0.5994 - val_loss: 1.3087 - val_accuracy: 0.5486\n",
            "Epoch 476/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1503 - accuracy: 0.5994 - val_loss: 1.4704 - val_accuracy: 0.5038\n",
            "Epoch 477/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1482 - accuracy: 0.6008 - val_loss: 1.4328 - val_accuracy: 0.5052\n",
            "Epoch 478/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1479 - accuracy: 0.6012 - val_loss: 1.5077 - val_accuracy: 0.4916\n",
            "Epoch 479/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1471 - accuracy: 0.6007 - val_loss: 1.3992 - val_accuracy: 0.5284\n",
            "Epoch 480/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1434 - accuracy: 0.6024 - val_loss: 2.2497 - val_accuracy: 0.3354\n",
            "Epoch 481/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1437 - accuracy: 0.5998 - val_loss: 1.4861 - val_accuracy: 0.5062\n",
            "Epoch 482/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1445 - accuracy: 0.6019 - val_loss: 1.4592 - val_accuracy: 0.5008\n",
            "Epoch 483/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1437 - accuracy: 0.6011 - val_loss: 1.7301 - val_accuracy: 0.4166\n",
            "Epoch 484/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1400 - accuracy: 0.6050 - val_loss: 1.4397 - val_accuracy: 0.5042\n",
            "Epoch 485/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1425 - accuracy: 0.5997 - val_loss: 1.3425 - val_accuracy: 0.5386\n",
            "Epoch 486/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1406 - accuracy: 0.6016 - val_loss: 1.5537 - val_accuracy: 0.4740\n",
            "Epoch 487/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1371 - accuracy: 0.6025 - val_loss: 1.4649 - val_accuracy: 0.5012\n",
            "Epoch 488/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1366 - accuracy: 0.6038 - val_loss: 1.3305 - val_accuracy: 0.5430\n",
            "Epoch 489/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1352 - accuracy: 0.6070 - val_loss: 1.5001 - val_accuracy: 0.4976\n",
            "Epoch 490/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1370 - accuracy: 0.6039 - val_loss: 1.4380 - val_accuracy: 0.5062\n",
            "Epoch 491/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1343 - accuracy: 0.6057 - val_loss: 1.3833 - val_accuracy: 0.5296\n",
            "Epoch 492/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1335 - accuracy: 0.6038 - val_loss: 1.3897 - val_accuracy: 0.5284\n",
            "Epoch 493/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1325 - accuracy: 0.6063 - val_loss: 1.4421 - val_accuracy: 0.5010\n",
            "Epoch 494/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1321 - accuracy: 0.6051 - val_loss: 1.4618 - val_accuracy: 0.5060\n",
            "Epoch 495/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1324 - accuracy: 0.6062 - val_loss: 1.3232 - val_accuracy: 0.5430\n",
            "Epoch 496/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1317 - accuracy: 0.6052 - val_loss: 1.4112 - val_accuracy: 0.5198\n",
            "Epoch 497/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1325 - accuracy: 0.6038 - val_loss: 1.3621 - val_accuracy: 0.5372\n",
            "Epoch 498/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1296 - accuracy: 0.6068 - val_loss: 1.3782 - val_accuracy: 0.5324\n",
            "Epoch 499/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1295 - accuracy: 0.6054 - val_loss: 1.3191 - val_accuracy: 0.5448\n",
            "Epoch 500/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1254 - accuracy: 0.6089 - val_loss: 1.3297 - val_accuracy: 0.5404\n",
            "Epoch 501/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1278 - accuracy: 0.6086 - val_loss: 1.3946 - val_accuracy: 0.5284\n",
            "Epoch 502/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1249 - accuracy: 0.6072 - val_loss: 1.3380 - val_accuracy: 0.5392\n",
            "Epoch 503/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1229 - accuracy: 0.6086 - val_loss: 1.5818 - val_accuracy: 0.4748\n",
            "Epoch 504/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1225 - accuracy: 0.6077 - val_loss: 1.4114 - val_accuracy: 0.5204\n",
            "Epoch 505/512\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1234 - accuracy: 0.6098 - val_loss: 1.3678 - val_accuracy: 0.5220\n",
            "Epoch 506/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1234 - accuracy: 0.6088 - val_loss: 1.3409 - val_accuracy: 0.5460\n",
            "Epoch 507/512\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1197 - accuracy: 0.6084 - val_loss: 1.3393 - val_accuracy: 0.5422\n",
            "Epoch 508/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1178 - accuracy: 0.6113 - val_loss: 1.3468 - val_accuracy: 0.5388\n",
            "Epoch 509/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1201 - accuracy: 0.6108 - val_loss: 1.5253 - val_accuracy: 0.4886\n",
            "Epoch 510/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1170 - accuracy: 0.6113 - val_loss: 1.4655 - val_accuracy: 0.5004\n",
            "Epoch 511/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1164 - accuracy: 0.6108 - val_loss: 1.4769 - val_accuracy: 0.4996\n",
            "Epoch 512/512\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1154 - accuracy: 0.6116 - val_loss: 1.5285 - val_accuracy: 0.4916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mrWK5hSB_o"
      },
      "source": [
        "## Defining Deeper Architectures: VGG Models\n",
        "\n",
        "*   Define a deeper model architecture for CIFAR-10 dataset and train the new model for 512 epochs with a batch size of 32. We will use VGG model as the architecture.\n",
        "\n",
        "**Stack two convolutional layers with 32 filters, each of 3 x 3. Use a max pooling layer and next flatten the output of the previous layer and add a dense layer with 128 units before the classification layer. For all the layers, use ReLU activation function. Use same padding for the layers to ensure that the height and width of each layer output matches the input**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A80vLxW9FIek"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgca5dUNSFNc"
      },
      "source": [
        "# solution\n",
        "model_VGG = Sequential()\n",
        "model_VGG.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_VGG.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_VGG.add(MaxPooling2D((2, 2)))\n",
        "model_VGG.add(Flatten())\n",
        "model_VGG.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model_VGG.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwaPphEBUtlC"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 512 epochs with a batch size of 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc2qtU0mUvVA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "455fe10a-b92d-4501-da2c-7ea1cdd2b9dd"
      },
      "source": [
        "# solution\n",
        "model_VGG.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_VGG = model_VGG.fit(x_train, y_train_cat, batch_size=32, epochs=512, validation_split=0.1)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/512\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 2/512\n",
            " 776/1407 [===============>..............] - ETA: 2s - loss: nan - accuracy: 0.1006"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5c56e9007c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_VGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory_VGG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_VGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cRr2ZFSFds"
      },
      "source": [
        "*   Compare the performance of both the models by plotting the loss and accuracy curves of both the training steps. Does the deeper model perform better? Comment on the observation.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8OSHAf5SJPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f36d2799-0a87-434c-f61f-530b810d7e2d"
      },
      "source": [
        "# solution\n",
        "plt.subplot(211)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.plot(history.history['loss'], color='blue', label='train')\n",
        "plt.plot(history_VGG.history['loss'], color='red', label='VGG train')\n",
        "\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title('Classification Accuracy')\n",
        "plt.plot(history.history['accuracy'], color='green', label='train')\n",
        "plt.plot(history_VGG.history['accuracy'], color='purple', label='VGG train')\n",
        "plt.show()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*With both models, the model is overfitting the data in very early epochs. However, the deeper model reaches the maximum accuracy in a fewer number of epochs than the more shallow layer.*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzXmO1WoSKMY"
      },
      "source": [
        "*   Use predict function to predict the output for the test split\n",
        "*   Plot the confusion matrix for the new model and comment on the class confusions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DObaoxhaSMUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "81944dd0-2462-4e28-80ca-957576f59bfa"
      },
      "source": [
        "# solution\n",
        "from customplots import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "preds = model_VGG.predict(x_test)\n",
        "\n",
        "predictions = [np.argmax(np.array(pred)) for pred in preds]\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_test, predictions), list(range(10)), False,'YlGnBu', 'Confusion matrix of VGG')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x1008 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUBrvRomU5O_"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwVz-FLSNG7"
      },
      "source": [
        "*    Print the test accuracy for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4WX3_uLSN5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a6076a-c119-426f-cd9e-084fbcbef8a8"
      },
      "source": [
        "# solution\n",
        "\n",
        "print(accuracy_score(y_test, predictions))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dySqfA6PVBjQ"
      },
      "source": [
        "## Define the complete VGG architecture.\n",
        "\n",
        "**Stack two convolutional layers with 64 filters, each of 3 x 3 followed by max pooling layer. Stack two more convolutional layers with 128 filters, each of 3 x 3, followed by max pooling, follwed by two more convolutional layers with 256 filters, each of 3 x 3, followed by max pooling. Flatten the output of the previous layer and add a dense layer with 128 units before the classification layer. For all the layers, use ReLU activation function. Use same padding for the layers to ensure that the height and width of each layer output matches the input**\n",
        "\n",
        "*   Change the size of input to 64 x 64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm35siILFNT0"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "2zKMQJgEkHeX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH4lDVBuVA_Q"
      },
      "source": [
        "# solution\n",
        "model_cVGG = Sequential()\n",
        "model_cVGG.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_cVGG.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_cVGG.add(MaxPooling2D((2, 2)))\n",
        "model_cVGG.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_cVGG.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_cVGG.add(MaxPooling2D((2, 2)))\n",
        "model_cVGG.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_cVGG.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "model_cVGG.add(MaxPooling2D((2, 2)))\n",
        "model_cVGG.add(Flatten())\n",
        "model_cVGG.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model_cVGG.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# model_cVGG = Sequential()\n",
        "# model_cVGG.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "# model_cVGG.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3), padding='same'))\n",
        "# model_cVGG.add(MaxPooling2D((2, 2)))\n",
        "# model_cVGG.add(Flatten())\n",
        "# model_cVGG.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model_cVGG.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_B8kJGWhcM"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 100 epochs with a batch size of 32.\n",
        "*   Predict the output for the test split and plot the confusion matrix for the new model and comment on the class confusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4elnDWnjEbmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25e2ac86-d6e7-47e4-8e1a-866bc7503dbf"
      },
      "source": [
        "# solution\n",
        "model_cVGG.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "# y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "history_cVGG = model_cVGG.fit(x_train, y_train_cat, batch_size=32, epochs=100, validation_split=0.1)\n",
        "\n",
        "preds = model_cVGG.predict(x_test)\n",
        "\n",
        "predictions = [np.argmax(np.array(pred)) for pred in preds]\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_test, predictions), list(range(10)), False,'YlGnBu', 'Confusion matrix of Complete VGG')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 16s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
            "Epoch 38/100\n",
            " 292/1407 [=====>........................] - ETA: 4s - loss: nan - accuracy: 0.1034"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2b8f47b42dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory_cVGG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dlzFt0SXGDQ"
      },
      "source": [
        "# Understanding deep networks\n",
        "\n",
        "*   What is the use of activation functions in network? Why is it needed?\n",
        "*   We have used softmax activation function in the exercise. There are other activation functions available too. What is the difference between sigmoid activation and softmax activation?\n",
        "*   What is the difference between categorical crossentropy and binary crossentropy loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPy_1EWXX6fp"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "It is not always necessary to train models from scratch. We can use the knowledge of networks trained on other tasks to learn the task at hand. In this exercise, we will explore the use of pre-trained weights and train on the CIFAR-10 dataset.\n",
        "\n",
        "*   Create a base imagenet pretrained InceptionV3 model.\n",
        "    *    Hint: Use tf.keras.applications to create the model\n",
        "    *    Pay attention to the include_top parameter.\n"
      ],
      "metadata": {
        "id": "x7JtHCmIxSmn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvJ-OYIt6FRp"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "base_layer = keras.applications.inception_v3.InceptionV3(include_top=False, classes=10, input_shape=(32,32,3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZPNmumpxJMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "317a9f69-97ab-4a6c-e113-6eae333388d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-31fcfc1798b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_tl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m       weights=weights)\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    374\u001b[0m         if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    375\u001b[0m             (input_shape[1] is not None and input_shape[1] < min_size)):\n\u001b[0;32m--> 376\u001b[0;31m           raise ValueError('Input size must be at least '\n\u001b[0m\u001b[1;32m    377\u001b[0m                            \u001b[0;34mf'{min_size}x{min_size}; Received: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                            f'input_shape={input_shape}')\n",
            "\u001b[0;31mValueError\u001b[0m: Input size must be at least 75x75; Received: input_shape=(32, 32, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Add a global average pooling layer, followed by a fully-connected layer with 1024 neurons and then the classification layer."
      ],
      "metadata": {
        "id": "Sq8urTnlx_ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "bottom_layers = Sequential()\n",
        "bottom_layers.add(GlobalAveragePooling2D((2, 2)))\n",
        "bottom_layers.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
        "bottom_layers.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "yTR4yCT-yPJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Train the model by freezing the base model. Train only the newly added layers.\n",
        "    *    Hint: Every layer has an attribute called 'trainable'\n",
        "*   Compile the model and train the model for a few epochs only."
      ],
      "metadata": {
        "id": "h_rjXkO-yPfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "base_layer.trainable = False\n",
        "model_tl = Sequential()\n",
        "model_tl.add(base_layer)\n",
        "model_tl.add(bottom_layers)\n",
        "\n",
        "model_tl.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_tl = model_tl.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "id": "3Szbku96ypDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Freeze the bottom layers and unfreeze the base layers.\n",
        "*    Compile and train the classifier with a very low learning rate (0.0001)"
      ],
      "metadata": {
        "id": "mlQ5-83TypWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "base_layer.trainable = True\n",
        "bottom_layers.trainable = False\n",
        "OR\n",
        "model_tl.base_layer.trainable = True\n",
        "model_tl.bottom_layers.trainable = False\n",
        "\n",
        "model_tl.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'], learning_rate = 1e-4)\n",
        "\n",
        "history_tl = model_tl.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "8p-0Jyi6zDWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Compare the performance of the VGG model and the Inception-V3 model."
      ],
      "metadata": {
        "id": "6C8rryZozCr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(211)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.plot(history_tl.history['loss'], color='blue', label='Transfer Learning train')\n",
        "plt.plot(history_VGG.history['loss'], color='red', label='VGG train')\n",
        "\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title('Classification Accuracy')\n",
        "plt.plot(history_tl.history['accuracy'], color='green', label='Transfer Learning train')\n",
        "plt.plot(history_VGG.history['accuracy'], color='purple', label='VGG train')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U_KVEvYXRKQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzhxMkt82ddr"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    When do we train models from scratch? What are the potential issues in training models from scratch?"
      ],
      "metadata": {
        "id": "gEA8k0BtzLyI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ECBMya2e1g"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Why do we use pre-trained weights?\n",
        "*    What is the difference between using random initialization and using weights from a pre-trained model?"
      ],
      "metadata": {
        "id": "arkQv6N_66n2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG2sGnxd64Sv"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-8E3dBw8Zoa"
      },
      "source": [
        "# Extracting features from Deep Networks\n",
        "\n",
        "It is quite possible to extract features (similar to SIFT or ORB) from different layers of deep network.\n",
        "\n",
        "*   Load ResNet50 model with imagenet weights and check the summary of the model\n",
        "*   Create a model to extract features from the 'avg_pool' layer.\n",
        "*   Extract features from the layer for all the train images.\n",
        "*   Use the extracted features to train a SVM classifier.\n",
        "    *    Use GridSearchCV and SVC to perform the classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ83bPO3mO16"
      },
      "source": [
        "# solution\n",
        "model_rn = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=None)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Evaluate the trained SVM model using the test set\n",
        "*    Calculate the accuracy score and confusion matrix"
      ],
      "metadata": {
        "id": "n3CeHn372_J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "\n"
      ],
      "metadata": {
        "id": "pRwVH6bc3Ob6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Visualizations\n",
        "\n",
        "In order to visualize the features of a higher dimension data, t-SNE is used. t-SNE converts the affinities of the data points to probabilities. It recreates the probability distribution in a low-dimensional space. It is very helpful in visualizing features of different layers in a neural network.\n",
        "\n",
        "You can find more information about t-SNE [here](https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne)"
      ],
      "metadata": {
        "id": "0iNWSH-M1Lv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Use TSNE to visualize the features extracted in the previous exercise.\n",
        "    *    Hint: TSNE function is available in the *sklearn.manifold* package."
      ],
      "metadata": {
        "id": "U84jVNvR39CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "\n"
      ],
      "metadata": {
        "id": "uNTOB1gN4RC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Why is feature visualization helpful?"
      ],
      "metadata": {
        "id": "pOYsp8jZ4Rce"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DlpPak4ZYG"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnN_t5Me7N5O"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **End of P4_1: Image Classification using CNN**\n",
        "Deadline for P4_1 submission in CampusVirtual is: **Monday, the 24th of November, 2022**"
      ]
    }
  ]
}