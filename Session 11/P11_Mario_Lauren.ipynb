{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mario-rot/ComputerVisionCourse-MAI/blob/main/Session%2011/P11_Mario_Lauren.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o1GwGEssa2j"
      },
      "source": [
        "# Laboratory #5_2 : Image Segmentation using UNet\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Segmentation using UNet\n",
        "*   Understand the evaluation metrics\n",
        "*   Importance of data annotations\n",
        "\n",
        "**Remember this is a graded exercise.**\n",
        "\n",
        "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
        "*   Create reusable functions where ever possible, so that the code could be reused at different places.\n",
        "*   Add sufficient comments and explanations wherever necessary.\n",
        "*   **Once you have the code completed, use GPU to train model faster.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zBfZflkZ4sN"
      },
      "source": [
        "# Loading dataset\n",
        "\n",
        "*   We will use the [Tray Food Segmentation dataset](https://www.kaggle.com/thezaza102/tray-food-segmentation) for this laboratory.\n",
        "*   You have two options to get the dataset into your notebook\n",
        "    *   The dataset is already available in campus virtual. Upload the dataset to your drive before starting the exercise.\n",
        "    *   You can use the kaggle APIs to get the dataset into the notebook directly (Advanced option)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10OQh5XmczVi"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git clone https://github.com/mario-rot/ComputerVisionCourse-MAI.git\n",
        "cd 'ComputerVisionCourse-MAI'\n",
        "mv 'Session 11/TrayDataset' /content/\n",
        "mv 'customplots.py' /content/\n",
        "mv 'utils.py' /content/"
      ],
      "metadata": {
        "id": "TbwTxbk2ETrZ",
        "outputId": "023b9aca-76b1-4878-f96a-c936538b6007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ComputerVisionCourse-MAI' already exists and is not an empty directory.\n",
            "mv: cannot stat 'Session 11/TrayDataset': No such file or directory\n",
            "mv: cannot stat 'customplots.py': No such file or directory\n",
            "mv: cannot stat 'utils.py': No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5e64cc36f9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"git clone https://github.com/mario-rot/ComputerVisionCourse-MAI.git\\ncd 'ComputerVisionCourse-MAI'\\nmv 'Session 11/TrayDataset' /content/\\nmv 'customplots.py' /content/\\nmv 'utils.py' /content/\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    135\u001b[0m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'git clone https://github.com/mario-rot/ComputerVisionCourse-MAI.git\ncd 'ComputerVisionCourse-MAI'\nmv 'Session 11/TrayDataset' /content/\nmv 'customplots.py' /content/\nmv 'utils.py' /content/\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUsFmBQM991i"
      },
      "source": [
        "# Constants\n",
        "\n",
        "*   Change the path of the directories according to your drive location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc36Vcmce_DR"
      },
      "source": [
        "import os\n",
        "\n",
        "root_path = r'/content/TrayDataset/'\n",
        "\n",
        "train_img = os.path.join(root_path, 'XTrain')\n",
        "train_mask = os.path.join(root_path, 'yTrain')\n",
        "test_img = os.path.join(root_path, 'XTest')\n",
        "test_mask = os.path.join(root_path, 'yTest')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JubjGi8QfeSK"
      },
      "source": [
        "*   Define the constants needed for training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2XDuHw3eeK9"
      },
      "source": [
        "img_size = (160, 160)\n",
        "num_classes = 43  # fixed for this dataset\n",
        "batch_size = 32\n",
        "epochs = 25"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvDvXEngeeK9"
      },
      "source": [
        "# Paths to Input Images and Segmentation Masks\n",
        "\n",
        "*   We prepare the list of images and masks for both the train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXgx3a1W951V",
        "outputId": "0701e108-58c4-4b0c-a066-a5f7ead2d443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "train_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(train_img, fname)\n",
        "        for fname in os.listdir(train_img)\n",
        "        if fname.endswith(\".jpg\") or fname.endswith(\".JPG\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_mask_paths = sorted(\n",
        "    [\n",
        "        os.path.join(train_mask, fname)\n",
        "        for fname in os.listdir(train_mask)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(test_img, fname)\n",
        "        for fname in os.listdir(test_img)\n",
        "        if fname.endswith(\".jpg\") or fname.endswith(\".JPG\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_mask_paths = sorted(\n",
        "    [\n",
        "        os.path.join(test_mask, fname)\n",
        "        for fname in os.listdir(test_mask)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of train samples:\", len(train_img_paths))\n",
        "print(\"Number of train masks:\", len(train_mask_paths))\n",
        "\n",
        "print(\"Number of test samples:\", len(test_img_paths))\n",
        "print(\"Number of test masks:\", len(test_mask_paths))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples: 1241\n",
            "Number of train masks: 1241\n",
            "Number of test samples: 8\n",
            "Number of test masks: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HnbWBareeK9"
      },
      "source": [
        "# Visualizing input image and corresponding segmentation mask\n",
        "\n",
        "*   Visualize one train image and the corresponding segmentation mask in a matplotlib subplot\n",
        "*   Also, show the mask overlayed on the original image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGZzIiceeeK9"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjmtLpA2eeK9"
      },
      "source": [
        "# Image Generator\n",
        "\n",
        "*   Create an image generator class (similar to the tutorial) to iterate over the images and return a tuple corresponding to the batch number.\n",
        "*   The generator should inherit from the Sequence class.\n",
        "*   It should have \\_\\_init\\_\\_(), \\_\\_len\\_\\_() and \\_\\_getitem\\_\\_() methods.\n",
        "*   The batch size, image size, image paths and mask paths should be initialized using the \\_\\_init\\_\\_ method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JlNR7yteeK9"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSj3e3TieeK9"
      },
      "source": [
        "# U-Net Xception-style model\n",
        "\n",
        "*   We will use the same model architecture that we followed in the tutorial for this exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAmTmywreeK9"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyaMy6rHJ24T"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "\n",
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMwalq3AJzV6"
      },
      "source": [
        "# Build model\n",
        "\n",
        "model = get_model(img_size, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mudxhXaXmQRN"
      },
      "source": [
        "*   Print the summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOfBJjCUEAkR"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qewnJAkaeeK9"
      },
      "source": [
        "# Instantiate Image Generators for each split\n",
        "\n",
        "*   For this experiment, we will use the test split as the validation generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c43PzegLeeK9"
      },
      "source": [
        "import random\n",
        "\n",
        "random.Random(1337).shuffle(train_img_paths)\n",
        "random.Random(1337).shuffle(train_mask_paths)\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = ImageGeneator(batch_size, img_size, train_img_paths, train_mask_paths)\n",
        "\n",
        "val_gen = ImageGeneator(batch_size, img_size, test_img_paths, test_mask_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFfhTs_zeeK9"
      },
      "source": [
        "# Train Model\n",
        "\n",
        "*   Configure the model for training\n",
        "    *   Use 'Sparse Categorical Crossentropy' loss for training\n",
        "    *   Use 'rmsprop' optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VssMYUeeK9"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE8nD0TFrs28"
      },
      "source": [
        "*   Instantiate a ModelCheckpoint callback to save only the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1UssfCVrobq"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5EKaY_2sEbP"
      },
      "source": [
        "*   Train the model using fit method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsPonCwYrq2R"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiaxFw19eeK9"
      },
      "source": [
        "# Visualize predictions\n",
        "\n",
        "*   Generate predictions for all images in the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSUUNqc26jRh"
      },
      "source": [
        "batch_size = 1  # we define batch_size as 1 for inferencing\n",
        "\n",
        "val_gen = ImageGeneator(batch_size, img_size, test_img_paths, test_mask_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtq3qvE5xKhF"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hewMZJJr7r-F"
      },
      "source": [
        "*   The mask is determined by the maximum value along the final axis. For all the predictions get the value of the predicted mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VOcSmAG6wxi"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "463_MLub-A3_"
      },
      "source": [
        "*   Read the test mask images to create the ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apD0cabF9gZK"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ximHk6P-39Q"
      },
      "source": [
        "*   For each validation image, find the jaccard similarity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6eBNwUi-u8d"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7BWMpm4iFQ1"
      },
      "source": [
        "*   What do you understand from the 'average' parameter of the Jaccard similarity score function?\n",
        "*   What are the different values of 'average' parameter? \n",
        "*   Which parameter is used for what type of problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lyt2KtJiEM_"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YM0os9UhYAJ"
      },
      "source": [
        "*   Randomly display one image, groundtruth mask, overlayed groundtruth mask, prediction mask, overlayed prediction mask using matplotlib "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CXTqOwHeeK9"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRIZChJchs-X"
      },
      "source": [
        "*   What are other evaluation metrics to compare the performance of segmentation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3cxHHrxjf8X"
      },
      "source": [
        "# Testing Model in the wild\n",
        "\n",
        "*   Download 5 images from the internet similar to the dataset used.\n",
        "*   Use the trained model to segment the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjCGUS9hhrE3"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyWdN9Foksy7"
      },
      "source": [
        "*   How accurate are the prediction masks?\n",
        "*   What happens to the unlabelled classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAO9wTaMlFq4"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqTdiCOcltn0"
      },
      "source": [
        "*   What are the challenges when you use a trained model in the wild?\n",
        "*   How can you develop a model to be used in real world?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRvzK4zMl1wh"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What is the difference between instance segmentation and semantic segmentation?"
      ],
      "metadata": {
        "id": "K2MMOQnpKSlv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE_xanr6M3j-"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What is the difference between encoder and decoder? Should they be of the same type of neural network?"
      ],
      "metadata": {
        "id": "LVKtKkrmK4yv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rggzKCVNM3yj"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What is upsampling?"
      ],
      "metadata": {
        "id": "1X3I4C0oLGsH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_3yxyTDM4Ku"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What are feature channels in UNet? Why is this helpful in this architecture?"
      ],
      "metadata": {
        "id": "FppsTWBWMbxm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guWhsJDNM4ei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What are some applications of U-Net?"
      ],
      "metadata": {
        "id": "A3geOD_UMsEd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqU0VyBMM431"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What are the other popular semantic segmentation algorithms?\n",
        "*   How are they different from each other?"
      ],
      "metadata": {
        "id": "rdkOj4eyvKEs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt__kf20vLcx"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What are the popular semantic segmentation datasets which are available for public access?"
      ],
      "metadata": {
        "id": "klr_TWjBvr4N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05OxWFIWvpJW"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnN_t5Me7N5O"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **End of P5_2: Image Segmentation using UNet**\n",
        "Deadline for P5_2 submission in CampusVirtual is: **Thursday, the 22nd of December, 2022**"
      ]
    }
  ]
}